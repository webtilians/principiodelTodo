"""
üî¨ AN√ÅLISIS PROFUNDO: Propagaci√≥n de la se√±al sem√°ntica en la arquitectura
==========================================================================

Objetivo: Rastrear c√≥mo el embedding sem√°ntico se propaga (o se pierde) a trav√©s de:
1. Input inicial
2. Forward pass (capas de la red)
3. Loss computation
4. Backward pass (gradientes)
5. Weight updates

M√©todo: Usar hooks de PyTorch para capturar activaciones en cada capa
"""

import torch
import torch.nn as nn
import sys
sys.path.append('src')

from infinito_gpt_text_fixed import InfinitoV51ConsciousnessBreakthrough, SemanticTextEmbedder
from argparse import Namespace
import numpy as np

class ActivationCapture:
    """Captura activaciones de capas espec√≠ficas"""
    def __init__(self):
        self.activations = {}
        self.hooks = []
    
    def register_hook(self, module, name):
        """Registra un hook para capturar la salida de un m√≥dulo"""
        def hook_fn(module, input, output):
            if isinstance(output, torch.Tensor):
                self.activations[name] = output.detach().clone()
            elif isinstance(output, tuple):
                self.activations[name] = output[0].detach().clone() if len(output) > 0 else None
        
        hook = module.register_forward_hook(hook_fn)
        self.hooks.append(hook)
        return hook
    
    def clear(self):
        """Limpia activaciones capturadas"""
        self.activations = {}
    
    def remove_hooks(self):
        """Remueve todos los hooks"""
        for hook in self.hooks:
            hook.remove()
        self.hooks = []

def analyze_signal_propagation():
    """
    Analiza c√≥mo se propaga la se√±al sem√°ntica a trav√©s de la arquitectura
    """
    
    print("="*80)
    print("üî¨ AN√ÅLISIS DE PROPAGACI√ìN DE SE√ëAL SEM√ÅNTICA")
    print("="*80)
    print()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    torch.manual_seed(42)
    
    # Textos con m√°xima diferencia sem√°ntica
    textos = [
        "mi perro es rojo",      # Animal + color c√°lido
        "yo pienso, luego existo"  # Filosof√≠a pura
    ]
    
    # Primero verificar que los embeddings son diferentes
    print("üîç PASO 1: Verificar embeddings sem√°nticos iniciales")
    print("-"*80)
    
    embedder = SemanticTextEmbedder(embed_dim=256, use_glove=False)
    
    emb1 = embedder.text_to_tensor(textos[0], device)
    emb2 = embedder.text_to_tensor(textos[1], device)
    
    diff_embedding = (emb1 - emb2).norm().item()
    
    print(f"\nüìù '{textos[0]}'")
    print(f"   Embedding norm: {emb1.norm().item():.6f}")
    print(f"   Embedding mean: {emb1.mean().item():.6f}")
    
    print(f"\nüìù '{textos[1]}'")
    print(f"   Embedding norm: {emb2.norm().item():.6f}")
    print(f"   Embedding mean: {emb2.mean().item():.6f}")
    
    print(f"\nüìä Diferencia entre embeddings: {diff_embedding:.6f}")
    
    if diff_embedding < 0.1:
        print("   ‚ùå Embeddings muy similares, an√°lisis puede no ser concluyente")
        return
    else:
        print("   ‚úÖ Embeddings suficientemente diferentes")
    
    # Crear modelo y registrar hooks
    print("\n" + "="*80)
    print("üîç PASO 2: Rastrear propagaci√≥n a trav√©s de la red")
    print("="*80)
    
    args = Namespace(
        batch_size=4,
        input_dim=256,
        hidden_dim=512,
        attention_heads=8,
        memory_slots=256,
        lr=1e-3,
        text_mode=True,
        input_text=None,
        quantum_active=False,
        target_consciousness=0.6,
        max_consciousness=0.9
    )
    
    results = {}
    
    for texto in textos:
        print(f"\n\n{'='*80}")
        print(f"üìù Procesando: '{texto}'")
        print('='*80)
        
        # Crear modelo fresh para cada texto
        model = InfinitoV51ConsciousnessBreakthrough(args)
        
        # Acceder al modelo interno (puede estar wrapped en DataParallel)
        net = model.model.module if hasattr(model.model, 'module') else model.model
        
        # Registrar hooks en capas clave
        capture = ActivationCapture()
        
        print("\nüé£ Registrando hooks en capas clave...")
        
        # Hook en las primeras capas de procesamiento
        if hasattr(net, 'visual_module') and hasattr(net.visual_module, 'dense_layers'):
            capture.register_hook(net.visual_module.dense_layers[0], 'visual_layer0')
            if len(net.visual_module.dense_layers) > 1:
                capture.register_hook(net.visual_module.dense_layers[-1], 'visual_layer_final')
        
        if hasattr(net, 'executive_module') and hasattr(net.executive_module, 'dense_layers'):
            capture.register_hook(net.executive_module.dense_layers[0], 'executive_layer0')
            if len(net.executive_module.dense_layers) > 1:
                capture.register_hook(net.executive_module.dense_layers[-1], 'executive_layer_final')
        
        # Hook en integraci√≥n consciente
        if hasattr(net, 'conscious_integration'):
            capture.register_hook(net.conscious_integration, 'conscious_integration')
        
        # Hook en memoria
        if hasattr(net, 'memory'):
            capture.register_hook(net.memory, 'memory_output')
        
        print(f"   ‚úÖ {len(capture.hooks)} hooks registrados")
        
        # Capturar input inicial
        with torch.no_grad():
            input_tensor = model.generate_text_based_input(texto)
            
            print(f"\nüì• Input inicial:")
            print(f"   Shape: {input_tensor.shape}")
            print(f"   Norm: {input_tensor.norm().item():.6f}")
            print(f"   Mean: {input_tensor.mean().item():.6f}")
            print(f"   Std: {input_tensor.std().item():.6f}")
        
        # Ejecutar UNA iteraci√≥n con captura de activaciones
        print(f"\nüîÑ Ejecutando forward pass...")
        
        model.optimizer.zero_grad()
        
        # Forward pass (sin train_step para control fino)
        with torch.set_grad_enabled(True):
            try:
                # Forward a trav√©s del modelo
                output = net(input_tensor)
                
                print(f"\nüì§ Output de la red:")
                print(f"   Shape: {output.shape}")
                print(f"   Norm: {output.norm().item():.6f}")
                print(f"   Mean: {output.mean().item():.6f}")
                print(f"   Std: {output.std().item():.6f}")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è Error en forward pass: {e}")
                capture.remove_hooks()
                continue
        
        # Analizar activaciones capturadas
        print(f"\nüìä Activaciones capturadas en capas intermedias:")
        print("-"*80)
        
        layer_stats = {}
        
        for layer_name, activation in capture.activations.items():
            if activation is not None:
                norm = activation.norm().item()
                mean = activation.mean().item()
                std = activation.std().item()
                
                layer_stats[layer_name] = {
                    'norm': norm,
                    'mean': mean,
                    'std': std,
                    'shape': activation.shape
                }
                
                print(f"\n   {layer_name}:")
                print(f"      Shape: {activation.shape}")
                print(f"      Norm:  {norm:.6f}")
                print(f"      Mean:  {mean:.6f}")
                print(f"      Std:   {std:.6f}")
        
        # Guardar resultados
        results[texto] = {
            'input_norm': input_tensor.norm().item(),
            'input_mean': input_tensor.mean().item(),
            'output_norm': output.norm().item() if output is not None else 0,
            'output_mean': output.mean().item() if output is not None else 0,
            'layer_stats': layer_stats,
            'embedding_raw': embedder.text_to_tensor(texto, device)
        }
        
        capture.remove_hooks()
    
    # An√°lisis comparativo
    print("\n\n" + "="*80)
    print("üìä AN√ÅLISIS COMPARATIVO ENTRE TEXTOS")
    print("="*80)
    
    texto1, texto2 = textos[0], textos[1]
    
    print(f"\nüî¥ INPUT (embeddings crudos):")
    emb_diff = (results[texto1]['embedding_raw'] - results[texto2]['embedding_raw']).norm().item()
    print(f"   L2 distance: {emb_diff:.6f}")
    
    print(f"\nüü° INPUT (post-transform en generate_text_based_input):")
    input_diff = abs(results[texto1]['input_norm'] - results[texto2]['input_norm'])
    print(f"   Norm difference: {input_diff:.6f}")
    print(f"   Texto 1 norm: {results[texto1]['input_norm']:.6f}")
    print(f"   Texto 2 norm: {results[texto2]['input_norm']:.6f}")
    
    print(f"\nüü¢ OUTPUT (salida final de la red):")
    output_diff = abs(results[texto1]['output_norm'] - results[texto2]['output_norm'])
    print(f"   Norm difference: {output_diff:.6f}")
    print(f"   Texto 1 norm: {results[texto1]['output_norm']:.6f}")
    print(f"   Texto 2 norm: {results[texto2]['output_norm']:.6f}")
    
    # Analizar p√©rdida de se√±al en cada capa
    print(f"\nüîµ CAPAS INTERMEDIAS:")
    
    common_layers = set(results[texto1]['layer_stats'].keys()) & set(results[texto2]['layer_stats'].keys())
    
    for layer_name in sorted(common_layers):
        stats1 = results[texto1]['layer_stats'][layer_name]
        stats2 = results[texto2]['layer_stats'][layer_name]
        
        diff_norm = abs(stats1['norm'] - stats2['norm'])
        diff_mean = abs(stats1['mean'] - stats2['mean'])
        
        print(f"\n   {layer_name}:")
        print(f"      Norm diff:  {diff_norm:.6f}")
        print(f"      Mean diff:  {diff_mean:.6f}")
        print(f"      Texto 1: norm={stats1['norm']:.4f}, mean={stats1['mean']:.4f}")
        print(f"      Texto 2: norm={stats2['norm']:.4f}, mean={stats2['mean']:.4f}")
    
    # Diagn√≥stico final
    print("\n\n" + "="*80)
    print("üéØ DIAGN√ìSTICO DE P√âRDIDA DE SE√ëAL")
    print("="*80)
    
    signal_loss_ratio = output_diff / emb_diff if emb_diff > 0 else 0
    
    print(f"\n1Ô∏è‚É£ Embedding crudo ‚Üí Input transformado:")
    if input_diff / emb_diff < 0.1:
        print(f"   ‚ùå P√âRDIDA CR√çTICA: {(1 - input_diff/emb_diff)*100:.1f}% de la se√±al")
        print(f"   ‚Üí El problema est√° en generate_text_based_input()")
    else:
        print(f"   ‚úÖ Se√±al preservada: {(input_diff/emb_diff)*100:.1f}% retenido")
    
    print(f"\n2Ô∏è‚É£ Input ‚Üí Output de la red:")
    if output_diff / input_diff < 0.1 if input_diff > 0 else False:
        print(f"   ‚ùå P√âRDIDA CR√çTICA en la red neuronal")
        print(f"   ‚Üí Las capas est√°n homogeneizando la se√±al")
    else:
        print(f"   ‚ö†Ô∏è Se√±al se mantiene parcialmente")
    
    print(f"\n3Ô∏è‚É£ Ratio de preservaci√≥n total (Embedding ‚Üí Output):")
    print(f"   Signal preservation: {signal_loss_ratio*100:.2f}%")
    
    if signal_loss_ratio < 0.01:
        print(f"\n‚ùå CONCLUSI√ìN: P√âRDIDA CATASTR√ìFICA DE SE√ëAL")
        print(f"   La diferencia sem√°ntica de {emb_diff:.4f} se reduce a {output_diff:.4f}")
        print(f"   Reducci√≥n de {(1-signal_loss_ratio)*100:.1f}%")
    elif signal_loss_ratio < 0.1:
        print(f"\n‚ö†Ô∏è CONCLUSI√ìN: P√âRDIDA SEVERA DE SE√ëAL")
        print(f"   La red homogeneiza las diferencias sem√°nticas")
    else:
        print(f"\n‚úÖ CONCLUSI√ìN: SE√ëAL SE PRESERVA PARCIALMENTE")
        print(f"   La red mantiene {signal_loss_ratio*100:.1f}% de la diferenciaci√≥n")
    
    # Identificar la capa m√°s problem√°tica
    print(f"\n4Ô∏è‚É£ Capa con mayor p√©rdida de se√±al:")
    
    if common_layers:
        max_loss_layer = None
        max_loss = 0
        
        for layer_name in common_layers:
            stats1 = results[texto1]['layer_stats'][layer_name]
            stats2 = results[texto2]['layer_stats'][layer_name]
            diff = abs(stats1['norm'] - stats2['norm'])
            
            if max_loss_layer is None or diff < max_loss:
                max_loss_layer = layer_name
                max_loss = diff
        
        print(f"   üî¥ {max_loss_layer}")
        print(f"      Diferencia m√≠nima: {max_loss:.6f}")
        print(f"      ‚Üí Esta capa homogeneiza m√°s que otras")

if __name__ == "__main__":
    analyze_signal_propagation()
