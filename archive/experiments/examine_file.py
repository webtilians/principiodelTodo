#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç VISOR INTERACTIVO DE RESULTADOS
================================

Herramienta para examinar cualquier archivo de resultados de manera detallada.
"""

import os
import json
import sys

def examine_file_interactive(file_path):
    """Examina un archivo de manera interactiva."""
    
    if not os.path.exists(file_path):
        print(f"‚ùå Archivo no encontrado: {file_path}")
        return
    
    print(f"üîç EXAMINANDO: {file_path}")
    print("=" * 70)
    
    # Informaci√≥n del archivo
    file_size = os.path.getsize(file_path)
    mod_time = os.path.getmtime(file_path)
    
    print(f"üìÅ Informaci√≥n del archivo:")
    print(f"   Tama√±o: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
    print(f"   Modificado: {datetime.fromtimestamp(mod_time)}")
    print()
    
    if file_path.endswith('.json'):
        examine_json_file(file_path)
    elif file_path.endswith('.pt'):
        examine_model_file(file_path)
    else:
        examine_text_file(file_path)

def examine_json_file(file_path):
    """Examina un archivo JSON en detalle."""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("üìã ESTRUCTURA JSON:")
        print_json_structure(data, indent=0, max_depth=3)
        print()
        
        # Detectar tipo de archivo
        if 'val_perplexity' in data:
            print("üîç TIPO DETECTADO: Historial de Entrenamiento")
            examine_training_history_detailed(data)
        elif any('generated' in str(v) for v in data.values() if isinstance(v, dict)):
            print("üîç TIPO DETECTADO: Comparaci√≥n de Modelos")
            examine_model_comparison_detailed(data)
        else:
            print("üîç TIPO DETECTADO: JSON Gen√©rico")
            examine_generic_json(data)
    
    except Exception as e:
        print(f"‚ùå Error leyendo JSON: {e}")

def print_json_structure(obj, indent=0, max_depth=3, current_depth=0):
    """Imprime la estructura de un objeto JSON."""
    
    if current_depth > max_depth:
        print("  " * indent + "... (contenido truncado)")
        return
    
    if isinstance(obj, dict):
        for key, value in obj.items():
            print("  " * indent + f"üìÇ {key}:", end="")
            
            if isinstance(value, dict):
                print(f" dict({len(value)} claves)")
                if current_depth < max_depth:
                    print_json_structure(value, indent + 1, max_depth, current_depth + 1)
            elif isinstance(value, list):
                print(f" list({len(value)} elementos)")
                if value and current_depth < max_depth:
                    print("  " * (indent + 1) + f"Ejemplo: {str(value[0])[:50]}...")
            else:
                print(f" {type(value).__name__}: {str(value)[:50]}{'...' if len(str(value)) > 50 else ''}")
    
    elif isinstance(obj, list):
        print("  " * indent + f"üìù Lista con {len(obj)} elementos")
        if obj and current_depth < max_depth:
            print("  " * indent + f"Primer elemento:")
            print_json_structure(obj[0], indent + 1, max_depth, current_depth + 1)

def examine_training_history_detailed(data):
    """Examina un historial de entrenamiento en detalle extremo."""
    
    print("\nüìà AN√ÅLISIS DETALLADO DEL ENTRENAMIENTO:")
    print("=" * 50)
    
    # M√©tricas b√°sicas
    if 'val_perplexity' in data:
        val_ppls = data['val_perplexity']
        train_ppls = data.get('train_perplexity', [])
        val_losses = data.get('val_loss', [])
        train_losses = data.get('train_loss', [])
        
        print("üìä ESTAD√çSTICAS GENERALES:")
        print(f"   Total de √©pocas: {len(val_ppls)}")
        print(f"   Perplexity validaci√≥n:")
        print(f"      Inicial: {val_ppls[0]:.4f}")
        print(f"      Final: {val_ppls[-1]:.4f}")
        print(f"      M√≠nima: {min(val_ppls):.4f} (√©poca {val_ppls.index(min(val_ppls)) + 1})")
        print(f"      M√°xima: {max(val_ppls):.4f} (√©poca {val_ppls.index(max(val_ppls)) + 1})")
        print()
        
        # An√°lisis de tendencias
        print("üìà AN√ÅLISIS DE TENDENCIAS:")
        
        # Calcular derivadas (cambios √©poca a √©poca)
        if len(val_ppls) > 1:
            changes = [val_ppls[i] - val_ppls[i-1] for i in range(1, len(val_ppls))]
            
            improvements = [c for c in changes if c < 0]
            degradations = [c for c in changes if c > 0]
            
            print(f"   √âpocas con mejora: {len(improvements)}")
            print(f"   √âpocas con empeoramiento: {len(degradations)}")
            print(f"   Cambio promedio por √©poca: {sum(changes)/len(changes):+.4f}")
            
            if improvements:
                print(f"   Mayor mejora: {min(improvements):+.4f}")
            if degradations:
                print(f"   Mayor empeoramiento: {max(degradations):+.4f}")
        print()
        
        # Tabla detallada √©poca por √©poca
        print("üìã TABLA DETALLADA:")
        print("   √âpoca |   Val PPL |  Train PPL |   Val Loss |  Train Loss | Cambio | Estado")
        print("   ------|-----------|------------|------------|-------------|--------|--------")
        
        for i in range(len(val_ppls)):
            epoch = i + 1
            val_ppl = val_ppls[i]
            train_ppl = train_ppls[i] if i < len(train_ppls) else None
            val_loss = val_losses[i] if i < len(val_losses) else None
            train_loss = train_losses[i] if i < len(train_losses) else None
            
            # Calcular cambio
            if i > 0:
                change = val_ppl - val_ppls[i-1]
                if change < -5:
                    status = "üöÄ Excelente"
                elif change < -1:
                    status = "‚úÖ Buena"
                elif change < 0:
                    status = "üìâ Mejora"
                elif change < 1:
                    status = "‚û°Ô∏è Estable"
                elif change < 5:
                    status = "‚ö†Ô∏è Empeora"
                else:
                    status = "üö® Malo"
            else:
                change = 0
                status = "üé¨ Inicio"
            
            print(f"   {epoch:5d} | {val_ppl:9.2f} | {train_ppl or 'N/A':>10} | "
                  f"{val_loss or 'N/A':>10} | {train_loss or 'N/A':>11} | {change:+6.2f} | {status}")
        print()
    
    # M√©tricas IIT si est√°n disponibles
    if 'train_phi' in data and data['train_phi']:
        phi_values = data['train_phi']
        loss_phi_values = data.get('train_loss_phi', [])
        
        print("üß† AN√ÅLISIS IIT DETALLADO:")
        print(f"   PHI Integration:")
        print(f"      Inicial: {phi_values[0]:.6f}")
        print(f"      Final: {phi_values[-1]:.6f}")
        print(f"      Evoluci√≥n: {phi_values[-1] - phi_values[0]:+.6f}")
        print(f"      Promedio: {sum(phi_values)/len(phi_values):.6f}")
        
        if loss_phi_values:
            print(f"   PHI Loss:")
            print(f"      Inicial: {loss_phi_values[0]:.6f}")
            print(f"      Final: {loss_phi_values[-1]:.6f}")
            print(f"      Reducci√≥n: {((loss_phi_values[0] - loss_phi_values[-1])/loss_phi_values[0]*100):.2f}%")
        print()
    
    # Learning rate evolution
    if 'learning_rate' in data and data['learning_rate']:
        lr_values = data['learning_rate']
        print("üìö EVOLUCI√ìN LEARNING RATE:")
        print(f"   Inicial: {lr_values[0]:.2e}")
        print(f"   Final: {lr_values[-1]:.2e}")
        
        # Detectar cambios de LR
        lr_changes = []
        for i in range(1, len(lr_values)):
            if lr_values[i] != lr_values[i-1]:
                lr_changes.append((i+1, lr_values[i-1], lr_values[i]))
        
        if lr_changes:
            print("   Cambios detectados:")
            for epoch, old_lr, new_lr in lr_changes:
                factor = new_lr / old_lr
                print(f"      √âpoca {epoch}: {old_lr:.2e} ‚Üí {new_lr:.2e} (factor: {factor:.2f})")
        else:
            print("   Sin cambios (LR constante)")
        print()

def examine_model_comparison_detailed(data):
    """Examina una comparaci√≥n de modelos en detalle."""
    
    print("\nüèÜ AN√ÅLISIS DETALLADO DE COMPARACI√ìN:")
    print("=" * 50)
    
    models_data = {}
    
    for model_name, model_info in data.items():
        if isinstance(model_info, dict) and 'avg_perplexity' in model_info:
            models_data[model_name] = model_info
    
    print(f"üìä MODELOS ANALIZADOS: {len(models_data)}")
    print()
    
    for model_name, model_info in models_data.items():
        print(f"ü§ñ {model_name.upper()}:")
        print(f"   Perplexity promedio: {model_info['avg_perplexity']:.4f}")
        
        if 'generations' in model_info:
            generations = model_info['generations']
            print(f"   Generaciones: {len(generations)}")
            
            # Estad√≠sticas de perplexity
            perplexities = [g.get('perplexity', 0) for g in generations]
            if perplexities:
                print(f"   PPL rango: {min(perplexities):.2f} - {max(perplexities):.2f}")
                print(f"   PPL mediana: {sorted(perplexities)[len(perplexities)//2]:.2f}")
            
            print("   üìù Todas las generaciones:")
            for i, gen in enumerate(generations, 1):
                prompt = gen.get('prompt', 'N/A')
                generated = gen.get('generated', 'N/A')
                ppl = gen.get('perplexity', 0)
                
                # Truncar texto para legibilidad
                prompt_short = prompt[:40] + "..." if len(prompt) > 40 else prompt
                generated_short = generated[:60] + "..." if len(generated) > 60 else generated
                
                quality = "üèÜ" if ppl < 50 else "üëç" if ppl < 200 else "‚ö†Ô∏è" if ppl < 1000 else "üí•"
                
                print(f"      {i}. {quality} \"{prompt_short}\"")
                print(f"         ‚Üí \"{generated_short}\" (PPL: {ppl:.2f})")
        
        print("-" * 50)
    
    # Ranking y comparaciones
    print("\nüèÜ RANKING DETALLADO:")
    sorted_models = sorted(models_data.items(), key=lambda x: x[1]['avg_perplexity'])
    
    for i, (model_name, model_info) in enumerate(sorted_models, 1):
        score = model_info['avg_perplexity']
        medal = ["ü•á", "ü•à", "ü•â"][i-1] if i <= 3 else f"{i}."
        
        # Calcular factor respecto al mejor
        best_score = sorted_models[0][1]['avg_perplexity']
        factor = score / best_score if best_score > 0 else float('inf')
        
        print(f"   {medal} {model_name}: {score:.4f} PPL (factor: {factor:.2f}x)")

def examine_model_file(file_path):
    """Examina un archivo de modelo (.pt)."""
    
    try:
        import torch
        checkpoint = torch.load(file_path, map_location='cpu', weights_only=False)
        
        print("üíæ AN√ÅLISIS DETALLADO DEL MODELO:")
        print("=" * 50)
        
        # Informaci√≥n b√°sica
        print("üìä INFORMACI√ìN GENERAL:")
        for key in ['epoch', 'val_loss', 'val_ppl']:
            if key in checkpoint:
                print(f"   {key}: {checkpoint[key]}")
        print()
        
        # Configuraci√≥n
        if 'config' in checkpoint:
            print("‚öôÔ∏è CONFIGURACI√ìN COMPLETA:")
            config = checkpoint['config']
            for key, value in config.items():
                print(f"   {key}: {value}")
            print()
        
        # An√°lisis del state_dict
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            
            print("üèóÔ∏è ARQUITECTURA DEL MODELO:")
            print(f"   Total de par√°metros: {sum(p.numel() for p in state_dict.values() if hasattr(p, 'numel')):,}")
            print()
            
            # Agrupar por tipos de capas
            layer_types = {}
            for name, tensor in state_dict.items():
                layer_type = name.split('.')[0] if '.' in name else name
                if layer_type not in layer_types:
                    layer_types[layer_type] = []
                layer_types[layer_type].append((name, tensor.shape, tensor.numel()))
            
            print("   üìã CAPAS POR TIPO:")
            for layer_type, layers in layer_types.items():
                total_params = sum(params for _, _, params in layers)
                print(f"      {layer_type}: {len(layers)} capas, {total_params:,} par√°metros")
                
                # Mostrar algunas capas representativas
                for name, shape, params in layers[:3]:
                    print(f"         {name}: {list(shape)} ({params:,} params)")
                if len(layers) > 3:
                    print(f"         ... y {len(layers) - 3} m√°s")
                print()
        
        # Historial si est√° disponible
        if 'history' in checkpoint:
            print("üìà HISTORIAL EMBEBIDO:")
            history = checkpoint['history']
            if 'val_perplexity' in history:
                val_ppls = history['val_perplexity']
                print(f"   √âpocas entrenadas: {len(val_ppls)}")
                print(f"   Progresi√≥n PPL: {val_ppls[0]:.2f} ‚Üí {val_ppls[-1]:.2f}")
            print()
    
    except Exception as e:
        print(f"‚ùå Error analizando modelo: {e}")

def examine_text_file(file_path):
    """Examina un archivo de texto."""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print("üìÑ AN√ÅLISIS DE ARCHIVO DE TEXTO:")
        print("=" * 50)
        
        lines = content.split('\n')
        words = content.split()
        
        print(f"   L√≠neas: {len(lines)}")
        print(f"   Palabras: {len(words)}")
        print(f"   Caracteres: {len(content)}")
        print()
        
        # Mostrar primeras l√≠neas
        print("üìñ PRIMERAS 10 L√çNEAS:")
        for i, line in enumerate(lines[:10], 1):
            print(f"   {i:2d}: {line[:100]}{'...' if len(line) > 100 else ''}")
        
        if len(lines) > 10:
            print(f"   ... y {len(lines) - 10} l√≠neas m√°s")
    
    except Exception as e:
        print(f"‚ùå Error leyendo archivo: {e}")

def main():
    """Funci√≥n principal."""
    
    from datetime import datetime
    
    if len(sys.argv) != 2:
        print("‚ùå Uso: python examine_file.py <ruta_archivo>")
        print("\nEjemplos:")
        print("   python examine_file.py models/checkpoints/infinito_v5.2_real_best.pt")
        print("   python examine_file.py results/training/training_history_real_20251115_170102.json")
        print("   python examine_file.py results/model_comparison_20251115_180340.json")
        return
    
    file_path = sys.argv[1]
    examine_file_interactive(file_path)

if __name__ == '__main__':
    main()