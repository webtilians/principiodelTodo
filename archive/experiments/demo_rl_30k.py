#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üé¨ DEMO - Generaci√≥n con Modelo RL 30K
======================================

Script de demostraci√≥n que muestra las capacidades del modelo RL 30K
con m√∫ltiples ejemplos de generaci√≥n.

Muestra:
- Diferentes tipos de prompts (cient√≠fico, creativo, filos√≥fico)
- Control adaptativo en acci√≥n
- Comparaci√≥n de m√©tricas
- An√°lisis de estrategias del agente
"""

from generate_with_rl_30k import RLTextGenerator
from datetime import datetime
import json

def print_header(title):
    """Imprimir encabezado bonito."""
    print("\n" + "="*70)
    print(f"  {title}")
    print("="*70)

def print_section(title):
    """Imprimir secci√≥n."""
    print(f"\n{'‚îÄ'*70}")
    print(f"  {title}")
    print(f"{'‚îÄ'*70}")

def analyze_strategy(result):
    """Analizar la estrategia del agente."""
    stats = result['stats']
    dist = stats['actions_distribution']
    
    text_pct = dist['TEXT']['percentage']
    phi_pct = dist['PHI']['percentage']
    mixed_pct = dist['MIXED']['percentage']
    
    print("\nüéØ An√°lisis de estrategia:")
    
    # Dominancia
    if max(text_pct, phi_pct, mixed_pct) == text_pct:
        print(f"  Estrategia dominante: TEXT ({text_pct:.1f}%)")
        print("  ‚Üí Prioriza calidad del lenguaje")
    elif max(text_pct, phi_pct, mixed_pct) == phi_pct:
        print(f"  Estrategia dominante: PHI ({phi_pct:.1f}%)")
        print("  ‚Üí Prioriza integraci√≥n de informaci√≥n")
    else:
        print(f"  Estrategia dominante: MIXED ({mixed_pct:.1f}%)")
        print("  ‚Üí Balance adaptativo equilibrado")
    
    # Balance
    balance = abs(text_pct - phi_pct)
    if balance < 10:
        print(f"  Balance TEXT/PHI: Muy equilibrado ({balance:.1f}% diff)")
    elif balance < 20:
        print(f"  Balance TEXT/PHI: Equilibrado ({balance:.1f}% diff)")
    else:
        print(f"  Balance TEXT/PHI: Desbalanceado ({balance:.1f}% diff)")
    
    # Exploraci√≥n
    if mixed_pct > 25:
        print(f"  Exploraci√≥n: Alta ({mixed_pct:.1f}% MIXED)")
    elif mixed_pct > 15:
        print(f"  Exploraci√≥n: Media ({mixed_pct:.1f}% MIXED)")
    else:
        print(f"  Exploraci√≥n: Baja ({mixed_pct:.1f}% MIXED)")
    
    # M√©tricas
    phi_ok = stats['phi_in_optimal_range_pct'] > 70
    ppl_ok = stats['perplexity_safe_pct'] > 90
    
    print(f"\n  Estado del sistema:")
    print(f"    PHI √≥ptimo: {stats['phi_in_optimal_range_pct']:5.1f}% {'‚úÖ' if phi_ok else '‚ö†Ô∏è'}")
    print(f"    PPL seguro: {stats['perplexity_safe_pct']:5.1f}% {'‚úÖ' if ppl_ok else '‚ö†Ô∏è'}")
    
    if phi_ok and ppl_ok:
        print(f"    Evaluaci√≥n: ‚úÖ EXCELENTE - Sistema estable y √≥ptimo")
    elif phi_ok or ppl_ok:
        print(f"    Evaluaci√≥n: ‚ö†Ô∏è ACEPTABLE - Revisi√≥n recomendada")
    else:
        print(f"    Evaluaci√≥n: ‚ùå PROBLEMAS - Requiere ajustes")

def demo_single_generation(generator, prompt, max_length=200, description=""):
    """Demo de una generaci√≥n individual."""
    print_section(f"Demo: {description}")
    print(f"\nPrompt: '{prompt}'")
    print(f"Max length: {max_length} tokens")
    print()
    
    result = generator.generate(
        prompt=prompt,
        max_length=max_length,
        verbose=False,
        return_metrics=True
    )
    
    # Mostrar texto generado
    print("\nüìÑ Texto generado:")
    print("‚îÄ" * 70)
    print(result['text'])
    print("‚îÄ" * 70)
    
    # Estad√≠sticas compactas
    stats = result['stats']
    print(f"\nüìä Estad√≠sticas r√°pidas:")
    print(f"  Tokens: {stats['tokens_generated']}")
    print(f"  Tiempo: {stats['duration_seconds']:.2f}s")
    print(f"  PHI medio: {stats['phi_mean']:.3f} (en [3-6]: {stats['phi_in_optimal_range_pct']:.0f}%)")
    print(f"  Reward total: {stats['total_reward']:+.3f}")
    
    # Distribuci√≥n visual
    dist = stats['actions_distribution']
    print(f"\n  Distribuci√≥n:")
    for action in ['TEXT', 'PHI', 'MIXED']:
        pct = dist[action]['percentage']
        bar = '‚ñà' * int(pct / 3)
        print(f"    {action:5s}: {pct:5.1f}% {bar}")
    
    # An√°lisis
    analyze_strategy(result)
    
    return result

def demo_comparative(generator):
    """Demo comparativo con m√∫ltiples prompts."""
    print_header("DEMO COMPARATIVO - Diferentes Tipos de Texto")
    
    test_cases = [
        {
            'prompt': "The nature of consciousness",
            'description': "Filos√≥fico/Abstracto",
            'max_length': 150
        },
        {
            'prompt': "Machine learning algorithms can",
            'description': "T√©cnico/Cient√≠fico",
            'max_length': 150
        },
        {
            'prompt': "Once upon a time in a distant galaxy",
            'description': "Narrativo/Creativo",
            'max_length': 150
        }
    ]
    
    results = []
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n\n{'='*70}")
        print(f"  TEST {i}/3: {case['description']}")
        print(f"{'='*70}")
        
        result = demo_single_generation(
            generator,
            prompt=case['prompt'],
            max_length=case['max_length'],
            description=case['description']
        )
        
        results.append({
            'case': case,
            'result': result
        })
    
    # Comparaci√≥n final
    print("\n\n" + "="*70)
    print("  COMPARACI√ìN FINAL")
    print("="*70)
    
    print("\nüìä Resumen comparativo:")
    print()
    print(f"{'Tipo':<20} {'TEXT%':>7} {'PHI%':>7} {'MIXED%':>7} {'Œ¶ medio':>8} {'Reward':>9}")
    print("‚îÄ" * 70)
    
    for item in results:
        desc = item['case']['description']
        stats = item['result']['stats']
        dist = stats['actions_distribution']
        
        print(f"{desc:<20} "
              f"{dist['TEXT']['percentage']:>6.1f}% "
              f"{dist['PHI']['percentage']:>6.1f}% "
              f"{dist['MIXED']['percentage']:>6.1f}% "
              f"{stats['phi_mean']:>8.3f} "
              f"{stats['total_reward']:>+9.3f}")
    
    # An√°lisis de patrones
    print("\nüí° Observaciones:")
    
    avg_text = sum(r['result']['stats']['actions_distribution']['TEXT']['percentage'] for r in results) / len(results)
    avg_phi = sum(r['result']['stats']['actions_distribution']['PHI']['percentage'] for r in results) / len(results)
    avg_mixed = sum(r['result']['stats']['actions_distribution']['MIXED']['percentage'] for r in results) / len(results)
    
    print(f"\n  Promedio global:")
    print(f"    TEXT:  {avg_text:5.1f}%")
    print(f"    PHI:   {avg_phi:5.1f}%")
    print(f"    MIXED: {avg_mixed:5.1f}%")
    
    if avg_mixed > 20:
        print(f"\n  ‚úÖ El agente usa bien el modo MIXED (adaptativo)")
    else:
        print(f"\n  ‚ö†Ô∏è El agente usa poco MIXED (menos de 20%)")
    
    # PHI
    phi_values = [r['result']['stats']['phi_mean'] for r in results]
    phi_avg = sum(phi_values) / len(phi_values)
    phi_std = (sum((x - phi_avg)**2 for x in phi_values) / len(phi_values)) ** 0.5
    
    print(f"\n  PHI medio global: {phi_avg:.3f} ¬± {phi_std:.3f}")
    if 3.0 <= phi_avg <= 6.0:
        print(f"  ‚úÖ PHI en rango √≥ptimo [3.0-6.0]")
    else:
        print(f"  ‚ö†Ô∏è PHI fuera de rango √≥ptimo")

def main():
    """Funci√≥n principal del demo."""
    print("="*70)
    print("  üé¨ DEMO - MODELO RL 30K √ìPTIMO")
    print("="*70)
    print(f"  Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  Modelo: PPO 30K steps (√≥ptimo)")
    print("="*70)
    
    try:
        # Crear generador
        print("\nüì¶ Inicializando generador...")
        generator = RLTextGenerator()
        
        # Cargar modelo
        print("‚è≥ Cargando modelo RL 30K...")
        generator.load()
        print("‚úÖ Modelo listo")
        
        # Demo 1: Generaci√≥n simple
        print_header("DEMO 1 - Generaci√≥n Simple")
        demo_single_generation(
            generator,
            prompt="The future of artificial intelligence",
            max_length=200,
            description="Demo b√°sico"
        )
        
        # Demo 2: Comparativo
        print("\n\n")
        demo_comparative(generator)
        
        # Demo 3: Diferentes configuraciones
        print("\n\n")
        print_header("DEMO 3 - Diferentes Temperaturas")
        
        temps = [0.5, 0.8, 1.2]
        prompt = "Consciousness emerges when"
        
        print(f"\nPrompt fijo: '{prompt}'")
        print(f"Temperaturas: {temps}")
        
        for temp in temps:
            print(f"\n\n{'‚îÄ'*70}")
            print(f"  Temperature = {temp}")
            print(f"{'‚îÄ'*70}")
            
            result = generator.generate(
                prompt=prompt,
                max_length=100,
                temperature=temp,
                verbose=False
            )
            
            print(f"\nTexto generado:")
            print(result['text'])
            print(f"\nReward total: {result['stats']['total_reward']:+.3f}")
            print(f"PHI medio: {result['stats']['phi_mean']:.3f}")
        
        # Resumen final
        print("\n\n" + "="*70)
        print("  ‚úÖ DEMO COMPLETADO")
        print("="*70)
        
        print("\nüí° Conclusiones:")
        print("  1. El modelo RL 30K ajusta autom√°ticamente TEXT/PHI/MIXED")
        print("  2. Mantiene PHI en rango √≥ptimo [3.0-6.0] >90% del tiempo")
        print("  3. Evita colapsos (PPL < 10) y confusi√≥n (PPL > 200)")
        print("  4. Adapta estrategia seg√∫n el tipo de texto")
        print("  5. Mayor temperatura = m√°s exploraci√≥n pero m√°s variabilidad")
        
        print("\nüìö Para m√°s informaci√≥n:")
        print("  - README_PRODUCCION_RL.md (gu√≠a de uso)")
        print("  - MODELO_30K_GUIA.md (detalles t√©cnicos)")
        print("  - RESUMEN_EJECUTIVO_RL_V2.md (resultados)")
        
        # Cerrar
        print("\nüßπ Liberando recursos...")
        generator.close()
        
        print("\n‚úÖ Demo finalizado exitosamente")
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())
