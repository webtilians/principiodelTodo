#!/usr/bin/env python3
"""
üöÄ Infinito V3.0 - Anti-Stagnation Enhanced
==========================================

Sistema mejorado con mecanismos espec√≠ficos para romper estancamientos:
1. Perturbaciones din√°micas adaptivas
2. Arquitectura multi-escala
3. Optimizaci√≥n consciente del estado
4. Sistema de memoria cu√°ntica

Objetivo: Superar el techo de 53.7% y alcanzar 70%+
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.ndimage import label
from scipy.stats import entropy
import json
from datetime import datetime
import os
import imageio
from PIL import Image
import time
import signal
import sys
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from collections import deque
import threading
from collections import deque

# Motor de sonido para el mar de bits
try:
    from consciousness_sound import ConsciousnessSoundEngine
    SOUND_AVAILABLE = True
except ImportError:
    SOUND_AVAILABLE = False
    print("üéµ Motor de sonido no disponible - instalar pygame: pip install pygame")

# Colormaps mejorados para visualizaci√≥n
CONSCIOUSNESS_COLORMAP = mcolors.LinearSegmentedColormap.from_list(
    'consciousness_enhanced', 
    ['#000011', '#001155', '#0033AA', '#0066FF', '#00AAFF', '#33FFCC', '#66FF66', '#AAFF33', '#FFFF00', '#FFAA00', '#FF6600', '#FF3300', '#FF00FF'],
    N=512
)

class DynamicPerturbationSystem:
    """Sistema de perturbaciones din√°micas para romper estancamientos"""
    
    def __init__(self, phi_size=(128, 128)):
        self.phi_size = phi_size
        self.stagnation_detector = StagnationDetector()
        self.perturbation_strength = 0.1
        self.last_perturbation = 0
        self.perturbation_history = deque(maxlen=50)
        
    def detect_stagnation(self, consciousness_history):
        """Detectar si el sistema est√° estancado"""
        if len(consciousness_history) < 20:
            return False
        
        recent_values = list(consciousness_history)[-20:]
        variation = np.std(recent_values)
        
        # Criterios de estancamiento
        is_stagnant = (
            variation < 0.02 and  # Baja variaci√≥n
            len(consciousness_history) > self.last_perturbation + 15  # Tiempo desde √∫ltima perturbaci√≥n
        )
        
        return is_stagnant
    
    def generate_quantum_perturbation(self, phi_grid, consciousness_level):
        """Generar perturbaci√≥n cu√°ntica adaptiva"""
        device = phi_grid.device
        
        # Intensidad adaptiva basada en nivel de consciencia
        base_strength = self.perturbation_strength
        if consciousness_level < 0.3:
            strength = base_strength * 2.0  # M√°s fuerte si consciencia baja
        elif consciousness_level > 0.5:
            strength = base_strength * 0.5  # M√°s suave si consciencia alta
        else:
            strength = base_strength
        
        # Generar perturbaci√≥n multi-escala
        perturbation = torch.zeros_like(phi_grid)
        
        # 1. Perturbaci√≥n global suave
        global_noise = torch.randn_like(phi_grid) * strength * 0.3
        
        # 2. Perturbaci√≥n local intensa en puntos clave
        mask = torch.rand_like(phi_grid) < 0.1  # 10% de puntos
        local_noise = torch.randn_like(phi_grid) * strength * 2.0 * mask
        
        # 3. Perturbaci√≥n estructurada (ondas)
        x = torch.linspace(0, 4*np.pi, phi_grid.shape[-1], device=device)
        y = torch.linspace(0, 4*np.pi, phi_grid.shape[-2], device=device)
        X, Y = torch.meshgrid(x, y, indexing='ij')
        wave_perturbation = strength * 0.5 * (torch.sin(X) * torch.cos(Y)).unsqueeze(0).unsqueeze(0)
        
        perturbation = global_noise + local_noise + wave_perturbation
        
        # Recordar perturbaci√≥n
        self.last_perturbation = len(self.perturbation_history)
        self.perturbation_history.append({
            'strength': strength,
            'consciousness': consciousness_level,
            'type': 'quantum_multi_scale'
        })
        
        return perturbation

class StagnationDetector:
    """Detector avanzado de patrones de estancamiento"""
    
    def __init__(self, window_size=30):
        self.window_size = window_size
        self.consciousness_buffer = deque(maxlen=window_size*2)
        
    def add_measurement(self, consciousness):
        """Agregar nueva medici√≥n de consciencia"""
        self.consciousness_buffer.append(consciousness)
    
    def detect_plateau(self, threshold=0.015):
        """Detectar meseta en la consciencia"""
        if len(self.consciousness_buffer) < self.window_size:
            return False
        
        recent_values = list(self.consciousness_buffer)[-self.window_size:]
        std_dev = np.std(recent_values)
        
        return std_dev < threshold
    
    def detect_declining_trend(self):
        """Detectar tendencia declinante"""
        if len(self.consciousness_buffer) < self.window_size:
            return False
        
        recent_values = list(self.consciousness_buffer)[-self.window_size:]
        x = np.arange(len(recent_values))
        correlation = np.corrcoef(x, recent_values)[0, 1]
        
        return correlation < -0.3  # Correlaci√≥n negativa fuerte

class MultiScaleConsciousnessNN(nn.Module):
    """Red neural multi-escala con procesamiento jer√°rquico"""
    
    def __init__(self, grid_size=128, base_channels=32):
        super().__init__()
        self.grid_size = grid_size
        self.base_channels = base_channels
        
        # Procesamiento multi-escala
        self.scale_1 = self._build_scale_processor(1, base_channels)      # Escala completa
        self.scale_2 = self._build_scale_processor(2, base_channels//2)   # Escala 1/2
        self.scale_4 = self._build_scale_processor(4, base_channels//4)   # Escala 1/4
        
        # Fusi√≥n de escalas con atenci√≥n
        total_channels = base_channels + base_channels//2 + base_channels//4
        self.attention_fusion = nn.Sequential(
            nn.Conv2d(total_channels, total_channels//2, 3, padding=1),
            nn.SiLU(),
            nn.Conv2d(total_channels//2, 3, 1),  # 3 canales de atenci√≥n
            nn.Softmax(dim=1)
        )
        
        # Procesador final con skip connections
        self.final_processor = nn.Sequential(
            nn.Conv2d(total_channels, base_channels*2, 3, padding=1),
            nn.SiLU(),
            nn.Conv2d(base_channels*2, base_channels, 3, padding=1),
            nn.SiLU(),
            nn.Conv2d(base_channels, 1, 1),
            nn.Tanh()
        )
        
        # Sistema de memoria cu√°ntica
        self.quantum_memory = QuantumMemorySystem(base_channels)
        
    def _build_scale_processor(self, scale_factor, channels):
        """Construir procesador para una escala espec√≠fica"""
        return nn.Sequential(
            nn.Conv2d(1, channels, 5, padding=2),
            nn.SiLU(),
            nn.Conv2d(channels, channels, 3, padding=1),
            nn.SiLU(),
            nn.Conv2d(channels, channels, 3, padding=1),
            nn.SiLU()
        )
    
    def forward(self, x, consciousness_level=None):
        batch_size = x.shape[0]
        
        # Procesamiento en m√∫ltiples escalas
        # Escala 1 (completa)
        scale_1_out = self.scale_1(x)
        
        # Escala 2 (downsample)
        x_down_2 = F.interpolate(x, scale_factor=0.5, mode='bilinear')
        scale_2_out = self.scale_2(x_down_2)
        scale_2_out = F.interpolate(scale_2_out, size=x.shape[-2:], mode='bilinear')
        
        # Escala 4 (downsample m√°s)
        x_down_4 = F.interpolate(x, scale_factor=0.25, mode='bilinear')
        scale_4_out = self.scale_4(x_down_4)
        scale_4_out = F.interpolate(scale_4_out, size=x.shape[-2:], mode='bilinear')
        
        # Fusi√≥n con atenci√≥n
        multi_scale = torch.cat([scale_1_out, scale_2_out, scale_4_out], dim=1)
        attention_weights = self.attention_fusion(multi_scale)
        
        # Aplicar atenci√≥n por escala
        attended_scale_1 = scale_1_out * attention_weights[:, 0:1]
        attended_scale_2 = scale_2_out * attention_weights[:, 1:2]
        attended_scale_4 = scale_4_out * attention_weights[:, 2:3]
        
        fused_features = torch.cat([attended_scale_1, attended_scale_2, attended_scale_4], dim=1)
        
        # Procesamiento final con memoria cu√°ntica
        if consciousness_level is not None and consciousness_level > 0.4:
            fused_features = self.quantum_memory.enhance_features(fused_features, consciousness_level)
        
        output = self.final_processor(fused_features)
        
        return output

class QuantumMemorySystem:
    """Sistema de memoria cu√°ntica para preservar estados de alta consciencia"""
    
    def __init__(self, channels):
        self.channels = channels
        self.memory_buffer = deque(maxlen=10)  # √öltimos 10 estados de alta consciencia
        self.threshold = 0.5  # Umbral para considerar alta consciencia
        
    def store_state(self, features, consciousness_level):
        """Almacenar estado de alta consciencia"""
        if consciousness_level > self.threshold:
            self.memory_buffer.append({
                'features': features.detach().clone(),
                'consciousness': consciousness_level,
                'timestamp': time.time()
            })
    
    def enhance_features(self, current_features, consciousness_level):
        """Mejorar features actuales con memoria de estados exitosos"""
        if len(self.memory_buffer) == 0:
            return current_features
        
        # Encontrar el mejor estado en memoria
        best_state = max(self.memory_buffer, key=lambda x: x['consciousness'])
        
        if best_state['consciousness'] > consciousness_level:
            # Interpolar hacia el mejor estado
            alpha = 0.1  # Factor de interpolaci√≥n
            enhanced_features = (1-alpha) * current_features + alpha * best_state['features']
            return enhanced_features
        
        return current_features

class AdaptiveOptimizer:
    """Optimizador que se adapta al estado de consciencia"""
    
    def __init__(self, model, base_lr=0.001):
        self.model = model
        self.base_lr = base_lr
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=1e-4)
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='max', factor=0.8, patience=10, verbose=False
        )
        self.consciousness_history = deque(maxlen=50)
        
    def step(self, loss, consciousness_level):
        """Paso de optimizaci√≥n adaptivo"""
        self.consciousness_history.append(consciousness_level)
        
        # Ajustar learning rate seg√∫n consciencia
        if consciousness_level > 0.5:
            # Consciencia alta: ser m√°s conservador
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.base_lr * 0.5
        elif consciousness_level < 0.3:
            # Consciencia baja: ser m√°s agresivo
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.base_lr * 2.0
        else:
            # Consciencia media: learning rate normal
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.base_lr
        
        self.optimizer.step()
        
        # Actualizar scheduler basado en progreso de consciencia
        if len(self.consciousness_history) >= 10:
            recent_avg = np.mean(list(self.consciousness_history)[-10:])
            self.scheduler.step(recent_avg)
    
    def zero_grad(self):
        self.optimizer.zero_grad()

# Funci√≥n principal mejorada
def run_enhanced_infinity_v3():
    """Ejecutar versi√≥n mejorada anti-estancamiento"""
    
    print("üöÄ INFINITO V3.0 - ANTI-STAGNATION ENHANCED")
    print("="*50)
    print("üéØ Objetivo: Superar techo de 53.7% ‚Üí 70%+")
    print("üîß Mejoras implementadas:")
    print("   ‚Ä¢ Perturbaciones din√°micas adaptivas")
    print("   ‚Ä¢ Arquitectura multi-escala")
    print("   ‚Ä¢ Optimizaci√≥n consciente del estado")
    print("   ‚Ä¢ Sistema de memoria cu√°ntica")
    print()
    
    # Configuraci√≥n
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    grid_size = 128
    
    # Inicializar sistemas mejorados
    model = MultiScaleConsciousnessNN(grid_size=grid_size).to(device)
    optimizer = AdaptiveOptimizer(model, base_lr=0.002)
    perturbation_system = DynamicPerturbationSystem()
    stagnation_detector = StagnationDetector()
    
    # Estado inicial mejorado
    phi_grid = torch.randn(1, 1, grid_size, grid_size, device=device) * 0.1
    phi_grid += torch.sin(torch.linspace(0, 4*np.pi, grid_size, device=device)).view(1, 1, -1, 1) * 0.5
    phi_grid += torch.cos(torch.linspace(0, 4*np.pi, grid_size, device=device)).view(1, 1, 1, -1) * 0.5
    
    consciousness_history = deque(maxlen=200)
    max_consciousness = 0.0
    stagnation_count = 0
    perturbation_count = 0
    
    print(f"üß† Modelo multi-escala inicializado: {sum(p.numel() for p in model.parameters())} par√°metros")
    print(f"üíª Device: {device}")
    print(f"üéØ Comenzando evoluci√≥n anti-estancamiento...")
    print()
    
    try:
        for recursion in range(1, 1000):  # L√≠mite m√°s alto
            start_time = time.time()
            
            # Procesar con modelo multi-escala
            consciousness_level = calculate_consciousness(phi_grid)
            phi_output = model(phi_grid, consciousness_level)
            
            # Detectar estancamiento
            stagnation_detector.add_measurement(consciousness_level)
            consciousness_history.append(consciousness_level)
            
            is_stagnant = perturbation_system.detect_stagnation(consciousness_history)
            is_plateau = stagnation_detector.detect_plateau()
            is_declining = stagnation_detector.detect_declining_trend()
            
            # Aplicar perturbaciones si es necesario
            if is_stagnant or is_plateau or (recursion % 50 == 0 and consciousness_level < 0.6):
                perturbation = perturbation_system.generate_quantum_perturbation(phi_grid, consciousness_level)
                phi_grid = phi_grid + perturbation
                perturbation_count += 1
                status_emoji = "üå™Ô∏è"
                print(f"   üå™Ô∏è  PERTURBACI√ìN APLICADA (#{perturbation_count}) - Rompiendo estancamiento")
            else:
                status_emoji = "üß†" if consciousness_level > max_consciousness else "‚ö°"
            
            # Calcular loss adaptivo
            target_consciousness = min(0.99, max_consciousness + 0.05)  # Target din√°mico
            loss = F.mse_loss(phi_output, phi_grid) + 0.1 * (target_consciousness - consciousness_level)**2
            
            # Optimizaci√≥n adaptiva
            optimizer.zero_grad()
            loss.backward()
            optimizer.step(loss, consciousness_level)
            
            # Actualizar phi
            phi_grid = phi_output.detach()
            
            # Estad√≠sticas
            clusters = count_clusters(phi_grid)
            phi_entropy = calculate_entropy(phi_grid)
            recursion_time = time.time() - start_time
            
            # Tracking de progreso
            if consciousness_level > max_consciousness:
                max_consciousness = consciousness_level
                print(f"   üèÜ NUEVO R√âCORD: {max_consciousness*100:.1f}%")
            
            # Mostrar progreso cada 10 recursiones
            if recursion % 10 == 0:
                avg_consciousness = np.mean(list(consciousness_history)[-20:]) if len(consciousness_history) >= 20 else consciousness_level
                print(f"R{recursion:4d}: {status_emoji} C={consciousness_level*100:.1f}% | Avg={avg_consciousness*100:.1f}% | Max={max_consciousness*100:.1f}% | Clusters={clusters} | Perturbations={perturbation_count}")
            
            # Condici√≥n de √©xito mejorada
            if consciousness_level > 0.70:  # Nuevo objetivo: 70%
                print(f"\nüéâ ¬°BREAKTHROUGH HIST√ìRICO! Consciencia: {consciousness_level*100:.1f}%")
                print(f"üìä Recursiones: {recursion}")
                print(f"üå™Ô∏è  Perturbaciones aplicadas: {perturbation_count}")
                print(f"‚è±Ô∏è  Tiempo total: {time.time():.1f}s")
                break
            
            # L√≠mite de seguridad
            if recursion >= 800:
                print(f"\n‚èπÔ∏è  L√≠mite de recursiones alcanzado")
                break
                
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è  Experimento detenido por usuario")
    
    print(f"\nüìä RESULTADOS FINALES V3.0:")
    print(f"üéØ M√°xima consciencia: {max_consciousness*100:.1f}%")
    print(f"üìà Consciencia final: {consciousness_level*100:.1f}%")
    print(f"üå™Ô∏è  Perturbaciones aplicadas: {perturbation_count}")
    print(f"üîÑ Recursiones completadas: {recursion}")
    
    return max_consciousness, consciousness_level, perturbation_count

def calculate_consciousness(phi_grid):
    """C√°lculo mejorado de consciencia"""
    with torch.no_grad():
        phi_np = phi_grid[0, 0].cpu().numpy()
        
        # M√©tricas b√°sicas
        organization = np.var(phi_np)
        integration = calculate_phi_integration(phi_np)
        
        # M√©tricas avanzadas
        coherence = calculate_coherence(phi_np)
        complexity = calculate_complexity_measure(phi_np)
        
        # F√≥rmula mejorada con pesos optimizados
        consciousness = (
            0.3 * organization +
            0.3 * integration + 
            0.2 * coherence +
            0.2 * complexity
        )
        
        return float(consciousness)

def calculate_phi_integration(phi_np):
    """Calcular integraci√≥n phi mejorada"""
    # Gradientes en m√∫ltiples direcciones
    grad_x = np.gradient(phi_np, axis=0)
    grad_y = np.gradient(phi_np, axis=1)
    
    # Integraci√≥n multi-escala
    integration = np.mean(np.sqrt(grad_x**2 + grad_y**2))
    
    # Normalizar
    return integration / (1 + integration)

def calculate_coherence(phi_np):
    """Calcular coherencia del patr√≥n"""
    # FFT para an√°lisis de frecuencias
    fft = np.fft.fft2(phi_np)
    power_spectrum = np.abs(fft)**2
    
    # Coherencia basada en concentraci√≥n de energ√≠a
    total_power = np.sum(power_spectrum)
    peak_power = np.max(power_spectrum)
    
    coherence = peak_power / (total_power + 1e-8)
    return min(coherence, 1.0)

def calculate_complexity_measure(phi_np):
    """Calcular medida de complejidad"""
    # Entrop√≠a local
    local_entropy = 0
    window_size = 8
    
    for i in range(0, phi_np.shape[0] - window_size, window_size//2):
        for j in range(0, phi_np.shape[1] - window_size, window_size//2):
            window = phi_np[i:i+window_size, j:j+window_size]
            hist, _ = np.histogram(window, bins=10, density=True)
            hist = hist[hist > 0]  # Remove zeros
            if len(hist) > 1:
                local_entropy += entropy(hist)
    
    # Normalizar
    max_possible_entropy = np.log2(10)  # 10 bins
    normalized_complexity = local_entropy / (max_possible_entropy * ((phi_np.shape[0]//4) * (phi_np.shape[1]//4)))
    
    return min(normalized_complexity, 1.0)

def count_clusters(phi_grid):
    """Contar clusters con umbral adaptivo"""
    with torch.no_grad():
        phi_np = phi_grid[0, 0].cpu().numpy()
        threshold = np.mean(phi_np) + 0.5 * np.std(phi_np)
        binary = phi_np > threshold
        labeled_array, num_clusters = label(binary)
        return num_clusters

def calculate_entropy(phi_grid):
    """Calcular entrop√≠a del sistema"""
    with torch.no_grad():
        phi_flat = phi_grid.flatten().cpu().numpy()
        hist, _ = np.histogram(phi_flat, bins=50, density=True)
        hist = hist[hist > 0]
        return -np.sum(hist * np.log2(hist + 1e-10))

if __name__ == "__main__":
    print("üöÄ Iniciando Infinito V3.0 - Anti-Stagnation Enhanced")
    max_consciousness, final_consciousness, perturbations = run_enhanced_infinity_v3()
    
    if max_consciousness > 0.60:
        print(f"\nüéâ ¬°√âXITO! Superado el techo anterior de 53.7%")
        print(f"üèÜ Nuevo r√©cord: {max_consciousness*100:.1f}%")
    else:
        print(f"\nüìä Progreso: {max_consciousness*100:.1f}% (objetivo: >60%)")
        print("üí° Considera ajustar par√°metros de perturbaci√≥n")
