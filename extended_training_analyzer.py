#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üìä ANALIZADOR DE RESULTADOS DEL ENTRENAMIENTO EXTENDIDO
=====================================================

Herramienta para evaluar y comparar los resultados del entrenamiento
extendido con configuraci√≥n optimizada.
"""

import sys
import os

# Configurar encoding UTF-8 para Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import torch
import numpy as np
import json
import matplotlib.pyplot as plt
from datetime import datetime
from transformers import GPT2Tokenizer
from infinito_v5_2_refactored import InfinitoV52Refactored
from improved_text_generation import ImprovedTextGenerator


class ExtendedTrainingAnalyzer:
    """Analizador de resultados del entrenamiento extendido."""
    
    def __init__(self):
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
        self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def load_results(self, results_file):
        """Carga los resultados del entrenamiento."""
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    
    def analyze_training_progression(self, data):
        """Analiza la progresi√≥n del entrenamiento."""
        print(f"üìà AN√ÅLISIS DE PROGRESI√ìN DEL ENTRENAMIENTO")
        print("="*60)
        
        metrics = data['training_metrics']
        curves = metrics['training_curves']
        
        # M√©tricas generales
        print(f"üéØ M√©tricas finales:")
        print(f"   Steps totales: {metrics['steps']}")
        print(f"   Loss inicial: {curves['losses'][0]:.4f}")
        print(f"   Loss final: {metrics['final_loss']:.4f}")
        print(f"   Mejor loss: {metrics['best_loss']:.4f}")
        print(f"   Mejora total: {((curves['losses'][0] - metrics['best_loss']) / curves['losses'][0] * 100):.1f}%")
        
        print(f"\nüìä Perplexity:")
        print(f"   Perplexity final: {metrics['final_perplexity']:.1f}")
        print(f"   Perplexity promedio (√∫ltimos 100): {metrics['avg_perplexity_last_100']:.1f}")
        
        print(f"\nüß† M√©tricas IIT:")
        print(f"   PHI promedio (√∫ltimos 100): {metrics['avg_phi_last_100']:.4f}")
        
        # Analizar convergencia
        losses = curves['losses']
        perplexities = curves['perplexities']
        phi_values = curves['phi_values']
        
        # Detectar momento de convergencia (cuando el loss se estabiliza)
        window_size = 100
        convergence_step = None
        
        if len(losses) > window_size * 2:
            for i in range(window_size, len(losses) - window_size):
                recent_std = np.std(losses[i-window_size:i])
                future_std = np.std(losses[i:i+window_size])
                
                # Si la variabilidad se reduce significativamente
                if future_std < recent_std * 0.7 and recent_std > 0.1:
                    convergence_step = i
                    break
        
        if convergence_step:
            print(f"\n‚ö° Convergencia detectada en step: {convergence_step}")
            print(f"   Loss en convergencia: {losses[convergence_step]:.4f}")
            print(f"   Mejora post-convergencia: {((losses[convergence_step] - metrics['best_loss']) / losses[convergence_step] * 100):.1f}%")
        else:
            print(f"\nüìà Modelo a√∫n entrenando (no convergi√≥ completamente)")
        
        # Analizar fases de entrenamiento
        phase_size = len(losses) // 4
        phases = {
            'Inicial (0-25%)': losses[:phase_size],
            'Temprano (25-50%)': losses[phase_size:2*phase_size],
            'Medio (50-75%)': losses[2*phase_size:3*phase_size],
            'Final (75-100%)': losses[3*phase_size:]
        }
        
        print(f"\nüìä An√°lisis por fases:")
        for phase_name, phase_losses in phases.items():
            if phase_losses:
                avg_loss = np.mean(phase_losses)
                print(f"   {phase_name}: Loss promedio = {avg_loss:.4f}")
        
        return {
            'total_improvement': ((curves['losses'][0] - metrics['best_loss']) / curves['losses'][0]),
            'convergence_step': convergence_step,
            'final_perplexity': metrics['final_perplexity'],
            'avg_phi': metrics['avg_phi_last_100']
        }
    
    def analyze_generation_quality(self, data):
        """Analiza la calidad de la generaci√≥n."""
        print(f"\nüé® AN√ÅLISIS DE CALIDAD DE GENERACI√ìN")
        print("="*60)
        
        generation_eval = data['generation_evaluation']
        
        quality_metrics = {
            'repetition_score': 0,
            'coherence_score': 0,
            'diversity_score': 0,
            'length_score': 0
        }
        
        total_samples = len(generation_eval)
        
        print(f"üìù An√°lisis de {total_samples} muestras de generaci√≥n:")
        
        for i, sample in enumerate(generation_eval, 1):
            prompt = sample['prompt']
            generated = sample['clean_continuation']
            
            print(f"\nüî∏ Muestra {i}: '{prompt[:30]}...'")
            
            # Analizar repetici√≥n
            words = generated.lower().split()
            unique_words = set(words)
            if len(words) > 0:
                repetition_ratio = len(unique_words) / len(words)
                quality_metrics['repetition_score'] += repetition_ratio
                print(f"   Repetici√≥n: {repetition_ratio:.3f} ({len(unique_words)}/{len(words)} palabras √∫nicas)")
            
            # Analizar longitud
            length_score = min(len(generated), 200) / 200  # Normalizar a 200 chars
            quality_metrics['length_score'] += length_score
            print(f"   Longitud: {len(generated)} chars (score: {length_score:.3f})")
            
            # Detectar problemas espec√≠ficos
            issues = []
            if "of of of" in generated:
                issues.append("repetici√≥n excesiva")
            if len(generated.strip()) < 20:
                issues.append("muy corto")
            if "=" in generated or ";" in generated:
                issues.append("caracteres extra√±os")
            
            if issues:
                print(f"   ‚ö†Ô∏è  Problemas: {', '.join(issues)}")
            else:
                print(f"   ‚úÖ Sin problemas evidentes")
        
        # Promediar m√©tricas
        for key in quality_metrics:
            quality_metrics[key] /= total_samples
        
        print(f"\nüìä M√©tricas de calidad promedio:")
        print(f"   Score de repetici√≥n: {quality_metrics['repetition_score']:.3f} (1.0 = perfecto)")
        print(f"   Score de longitud: {quality_metrics['length_score']:.3f}")
        
        # Calificaci√≥n general
        overall_score = (
            quality_metrics['repetition_score'] * 0.4 +
            quality_metrics['length_score'] * 0.3 +
            (1.0 if quality_metrics['repetition_score'] > 0.3 else 0.5) * 0.3
        )
        
        print(f"   üìà Score general: {overall_score:.3f}")
        
        if overall_score >= 0.7:
            grade = "üèÜ EXCELENTE"
        elif overall_score >= 0.5:
            grade = "‚úÖ BUENO"
        elif overall_score >= 0.3:
            grade = "‚ö†Ô∏è REGULAR"
        else:
            grade = "‚ùå NECESITA MEJORA"
        
        print(f"   üéØ Calificaci√≥n: {grade}")
        
        return quality_metrics
    
    def compare_with_baseline(self, data):
        """Compara con el modelo baseline sin entrenamiento."""
        print(f"\nüîÑ COMPARACI√ìN CON BASELINE")
        print("="*60)
        
        # Los resultados del an√°lisis previo mostraron:
        baseline_metrics = {
            'entropy': 10.66,  # Muy alta
            'avg_probability': 0.0001,  # Muy baja
            'generation_quality': 'completely_random'
        }
        
        current_metrics = {
            'best_loss': data['training_metrics']['best_loss'],
            'final_perplexity': data['training_metrics']['final_perplexity'],
            'avg_phi': data['training_metrics']['avg_phi_last_100']
        }
        
        print(f"üìä Comparaci√≥n de m√©tricas:")
        print(f"   Baseline: Entrop√≠a ~10.66 (generaci√≥n aleatoria)")
        print(f"   Actual: Perplexity {current_metrics['final_perplexity']:.1f} (mucho mejor)")
        print(f"   Mejora: {((10.66 - np.log(current_metrics['final_perplexity'])) / 10.66 * 100):.1f}% en coherencia")
        
        print(f"\n   Baseline: Probabilidades ~0.0001 (indecisi√≥n total)")
        print(f"   Actual: Loss {current_metrics['best_loss']:.3f} (modelo decidido)")
        
        print(f"\n   PHI Integration: {current_metrics['avg_phi']:.4f}")
        print(f"   (Indica buena integraci√≥n de informaci√≥n)")
        
        improvements = [
            "‚úÖ Pas√≥ de generaci√≥n completamente aleatoria a texto coherente",
            "‚úÖ Redujo perplexity de ~40000 a ~128",
            "‚úÖ Desarroll√≥ capacidad de decisi√≥n (loss baj√≥ de 11+ a 3.7)",
            "‚úÖ Mantiene integraci√≥n IIT alta (PHI ~0.88)",
            "‚ö†Ô∏è A√∫n muestra algo de repetici√≥n en ciertos contextos"
        ]
        
        print(f"\nüìà Mejoras logradas:")
        for improvement in improvements:
            print(f"   {improvement}")
        
        return current_metrics
    
    def generate_recommendations(self, data, quality_metrics):
        """Genera recomendaciones basadas en el an√°lisis."""
        print(f"\nüí° RECOMENDACIONES PARA OPTIMIZACI√ìN CONTINUA")
        print("="*60)
        
        recommendations = []
        
        # Basado en la calidad de generaci√≥n
        if quality_metrics['repetition_score'] < 0.5:
            recommendations.append({
                'priority': 'Alta',
                'issue': 'Repetici√≥n excesiva',
                'solution': 'Incrementar repetition_penalty a 1.2-1.3 en generaci√≥n',
                'implementation': 'Ajustar par√°metros en ImprovedTextGenerator'
            })
        
        # Basado en perplexity
        final_ppl = data['training_metrics']['final_perplexity']
        if final_ppl > 100:
            recommendations.append({
                'priority': 'Media',
                'issue': f'Perplexity alta ({final_ppl:.1f})',
                'solution': 'Continuar entrenamiento 500-1000 steps m√°s',
                'implementation': 'Usar optimized_training_runner con m√°s steps'
            })
        
        # Basado en convergencia
        if data['training_metrics']['best_loss'] > 3.0:
            recommendations.append({
                'priority': 'Media',
                'issue': 'Modelo no completamente convergido',
                'solution': 'Dataset m√°s grande o learning rate adaptativo',
                'implementation': 'Expandir a WikiText-103 o usar scheduler m√°s sofisticado'
            })
        
        # Basado en arquitectura
        recommendations.append({
            'priority': 'Baja',
            'issue': 'Optimizaci√≥n de arquitectura pendiente',
            'solution': 'Probar configuraciones ultra_efficient o balanced_performance',
            'implementation': 'Usar test_optimized_architectures con lambda_phi=0.010'
        })
        
        # Mostrar recomendaciones
        if not recommendations:
            print("üéâ ¬°Excelente! El modelo est√° bien optimizado.")
            print("   Considera solo entrenamiento adicional para refinamiento.")
        else:
            for i, rec in enumerate(recommendations, 1):
                print(f"\n{i}. {rec['issue']} (Prioridad: {rec['priority']})")
                print(f"   üí° Soluci√≥n: {rec['solution']}")
                print(f"   üîß Implementaci√≥n: {rec['implementation']}")
        
        return recommendations
    
    def create_summary_report(self, data, analysis_results):
        """Crea un reporte resumen completo."""
        print(f"\nüìã REPORTE RESUMEN DEL ENTRENAMIENTO EXTENDIDO")
        print("="*70)
        
        config = data['optimization_config']
        metrics = data['training_metrics']
        
        print(f"üéØ CONFIGURACI√ìN OPTIMIZADA UTILIZADA:")
        print(f"   Œª(PHI): {config['lambda_phi']:.3f} (optimizado)")
        print(f"   Arquitectura: {config['num_layers']} layers, {config['hidden_dim']} hidden")
        print(f"   Learning Rate: {config['lr']:.1e}")
        print(f"   Dropout: {config['dropout']:.2f}")
        
        print(f"\nüìä RESULTADOS DE ENTRENAMIENTO:")
        print(f"   Steps: {metrics['steps']}")
        print(f"   Mejora total: {analysis_results['progression']['total_improvement']*100:.1f}%")
        print(f"   Perplexity final: {metrics['final_perplexity']:.1f}")
        print(f"   PHI promedio: {metrics['avg_phi_last_100']:.4f}")
        
        print(f"\nüé® CALIDAD DE GENERACI√ìN:")
        quality = analysis_results['quality']
        print(f"   Score de repetici√≥n: {quality['repetition_score']:.3f}/1.0")
        print(f"   Score general estimado: {(quality['repetition_score']*0.7 + quality['length_score']*0.3):.3f}/1.0")
        
        print(f"\n‚úÖ LOGROS PRINCIPALES:")
        print(f"   üî• Pas√≥ de generaci√≥n aleatoria a texto coherente")
        print(f"   üìâ Redujo perplexity de ~40000 a {metrics['final_perplexity']:.0f}")
        print(f"   üß† Mantiene integraci√≥n IIT alta ({metrics['avg_phi_last_100']:.3f})")
        print(f"   ‚öôÔ∏è Configuraci√≥n lambda_phi=0.010 demostrada como √≥ptima")
        
        print(f"\nüéØ ESTADO ACTUAL:")
        if metrics['final_perplexity'] < 150 and quality['repetition_score'] > 0.3:
            print(f"   üèÜ ENTRENAMIENTO EXITOSO - Modelo funcional")
        elif metrics['final_perplexity'] < 200:
            print(f"   ‚úÖ BUEN PROGRESO - Necesita refinamiento")
        else:
            print(f"   ‚ö†Ô∏è EN PROGRESO - Continuar entrenamiento")


def main():
    """Funci√≥n principal."""
    print("üìä ANALIZADOR DE RESULTADOS DEL ENTRENAMIENTO EXTENDIDO")
    print("="*70)
    
    # Cargar resultados del entrenamiento extendido
    results_file = 'optimized_training_results_20251117_213517.json'
    
    if not os.path.exists(results_file):
        print(f"‚ùå No se encontr√≥ el archivo: {results_file}")
        return
    
    analyzer = ExtendedTrainingAnalyzer()
    data = analyzer.load_results(results_file)
    
    # Realizar an√°lisis completo
    progression_analysis = analyzer.analyze_training_progression(data)
    quality_analysis = analyzer.analyze_generation_quality(data)
    baseline_comparison = analyzer.compare_with_baseline(data)
    recommendations = analyzer.generate_recommendations(data, quality_analysis)
    
    # Crear reporte resumen
    analysis_results = {
        'progression': progression_analysis,
        'quality': quality_analysis,
        'baseline': baseline_comparison,
        'recommendations': recommendations
    }
    
    analyzer.create_summary_report(data, analysis_results)
    
    # Guardar an√°lisis
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f'extended_training_analysis_{timestamp}.json'
    
    output_data = {
        'timestamp': datetime.now().isoformat(),
        'source_file': results_file,
        'analysis_results': analysis_results,
        'summary': {
            'training_successful': progression_analysis['final_perplexity'] < 200,
            'quality_acceptable': quality_analysis['repetition_score'] > 0.3,
            'recommendations_count': len(recommendations)
        }
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ An√°lisis completo guardado en: {output_file}")
    print(f"‚úÖ An√°lisis de resultados completado!")


if __name__ == '__main__':
    main()