#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üèÜ ENTRENAMIENTO CON GOLDEN SEED 2
===================================

Este script entrena el modelo IIT usando la inicializaci√≥n ganadora
(Golden Seed 2) que garantiza ~30% de mejora sobre baseline.

Compara:
- Modelo con Golden Seed 2 (garantizado ganador)
- Baseline sin Golden Seed (est√°ndar)
"""

import sys
import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import random
import numpy as np
from tqdm import tqdm
from datetime import datetime

# Configurar encoding UTF-8 para Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Importar modelo
sys.path.insert(0, os.path.dirname(__file__))
from infinito_v5_2_refactored import InfinitoV52Refactored


# =============================================================================
# GENERACI√ìN DE DATOS (DYCK LANGUAGE)
# =============================================================================

def generate_dyck_sample(max_depth=12, noise_len=6):
    """Genera secuencias Dyck con profundidad y ruido."""
    pairs = [('(', ')'), ('[', ']'), ('{', '}'), ('<', '>')]
    depth = random.randint(4, max_depth)
    stack = []
    sequence = []
    
    for _ in range(depth):
        pair = random.choice(pairs)
        sequence.append(pair[0])
        stack.append(pair[1])
    
    noise = [random.choice(['A', 'B', 'C']) for _ in range(noise_len)]
    input_str = sequence + noise
    target_str = list(reversed(stack))
    
    return input_str, target_str


vocab = {'PAD': 0, '(': 1, ')': 2, '[': 3, ']': 4, '{': 5, '}': 6, '<': 7, '>': 8, 
         'A': 9, 'B': 10, 'C': 11, 'EOS': 12}
idx_to_char = {v: k for k, v in vocab.items()}


def get_batch(batch_size=32):
    """Genera un batch de datos."""
    inputs = []
    targets = []
    for _ in range(batch_size):
        inp, tar = generate_dyck_sample()
        inp_ids = [vocab[c] for c in inp]
        tar_ids = [vocab[c] for c in tar] + [vocab['EOS']]
        
        inputs.append(torch.tensor(inp_ids))
        targets.append(torch.tensor(tar_ids))
        
    inp_tens = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)
    tar_tens = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)
    return inp_tens, tar_tens


# =============================================================================
# ENTRENAMIENTO
# =============================================================================

def train_model(model, epochs, device, model_name="Model"):
    """Entrena un modelo y retorna su historial."""
    optimizer = optim.AdamW(model.parameters(), lr=0.0005)
    criterion = nn.CrossEntropyLoss(ignore_index=0)
    history = []
    
    pbar = tqdm(range(epochs), desc=model_name)
    for epoch in pbar:
        input_ids, target_ids = get_batch(32)
        input_ids, target_ids = input_ids.to(device), target_ids.to(device)
        
        optimizer.zero_grad()
        logits, metrics = model(input_ids, return_metrics=True)
        min_len = min(logits.shape[1], target_ids.shape[1])
        loss = criterion(logits[:, :min_len, :].transpose(1, 2), target_ids[:, :min_len])
        
        # Agregar loss auxiliar si existe
        if metrics and 'delta_phi_loss' in metrics:
            loss_total = loss + (0.0 * metrics['delta_phi_loss'])
        else:
            loss_total = loss
        
        loss_total.backward()
        optimizer.step()
        
        history.append(loss.item())
        
        if epoch % 100 == 0:
            pbar.set_description(f"{model_name} | Loss: {loss.item():.4f}")
    
    return history


def main():
    """Funci√≥n principal de entrenamiento."""
    print("="*80)
    print("üèÜ ENTRENAMIENTO CON GOLDEN SEED 2 vs BASELINE")
    print("="*80)
    
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nüñ•Ô∏è  Dispositivo: {DEVICE}")
    
    EPOCHS = 3000
    print(f"‚è±Ô∏è  √âpocas: {EPOCHS}")
    
    # Configuraci√≥n del modelo
    config = {
        'vocab_size': 13,
        'hidden_dim': 64,
        'num_layers': 2,
        'num_heads': 4,
        'use_improved_memory': True,
        'use_improved_iit': True,
        'use_learnable_phi': True,
        'use_stochastic_exploration': True,
        'lambda_phi': 0.0
    }
    
    # ==========================================================================
    # MODELO 1: CON GOLDEN SEED 2 (Garant√≠a de 30% mejora)
    # ==========================================================================
    print("\n" + "="*80)
    print("üéØ MODELO 1: IIT CON GOLDEN SEED 2")
    print("="*80)
    
    model_golden = InfinitoV52Refactored(
        vocab_size=config['vocab_size'],
        hidden_dim=config['hidden_dim'],
        num_layers=config['num_layers'],
        num_heads=config['num_heads'],
        use_improved_memory=config['use_improved_memory'],
        use_improved_iit=config['use_improved_iit'],
        use_learnable_phi=config['use_learnable_phi'],
        use_stochastic_exploration=config['use_stochastic_exploration'],
        lambda_phi=config['lambda_phi']
    ).to(DEVICE)
    
    # üèÜ CARGAR GOLDEN SEED
    golden_path = '../models/golden_seed2_init.pt'
    if not os.path.exists(golden_path):
        print(f"‚ùå ERROR: No se encuentra {golden_path}")
        print("   Ejecuta primero: python extract_golden_seed.py")
        return
    
    golden_checkpoint = torch.load(golden_path, weights_only=False)
    model_golden.load_state_dict(golden_checkpoint['model_state_dict'])
    
    print(f"‚úÖ Golden Seed 2 cargada desde {golden_path}")
    print(f"   Memory Gate inicial: {model_golden.memory_gate.item():.6f}")
    print(f"   Rendimiento hist√≥rico: +29.14% sobre baseline")
    
    # ==========================================================================
    # MODELO 2: BASELINE (Sin Golden Seed)
    # ==========================================================================
    print("\n" + "="*80)
    print("üìä MODELO 2: BASELINE (inicializaci√≥n aleatoria est√°ndar)")
    print("="*80)
    
    model_baseline = InfinitoV52Refactored(
        vocab_size=config['vocab_size'],
        hidden_dim=config['hidden_dim'],
        num_layers=config['num_layers'],
        num_heads=config['num_heads'],
        use_improved_memory=False,
        use_improved_iit=False,
        use_learnable_phi=False,
        use_stochastic_exploration=False
    ).to(DEVICE)
    
    print(f"‚úÖ Baseline creado con inicializaci√≥n est√°ndar")
    
    # ==========================================================================
    # ENTRENAMIENTO
    # ==========================================================================
    print("\n" + "="*80)
    print("üöÄ INICIANDO ENTRENAMIENTO")
    print("="*80)
    
    print("\n[1/2] Entrenando Baseline...")
    history_baseline = train_model(model_baseline, EPOCHS, DEVICE, "Baseline")
    
    print("\n[2/2] Entrenando con Golden Seed 2...")
    history_golden = train_model(model_golden, EPOCHS, DEVICE, "Golden Seed")
    
    # ==========================================================================
    # RESULTADOS
    # ==========================================================================
    print("\n" + "="*80)
    print("üèÅ RESULTADOS FINALES")
    print("="*80)
    
    loss_baseline_final = history_baseline[-1]
    loss_golden_final = history_golden[-1]
    improvement = ((loss_baseline_final - loss_golden_final) / loss_baseline_final) * 100
    
    print(f"\nüìä Loss Final:")
    print(f"   Baseline:    {loss_baseline_final:.5f}")
    print(f"   Golden Seed: {loss_golden_final:.5f}")
    print(f"\nüöÄ MEJORA: {improvement:.2f}%")
    
    memory_gate_final = model_golden.memory_gate.item()
    memory_gate_activated = torch.sigmoid(model_golden.memory_gate).item()
    
    print(f"\nüö™ Memory Gate:")
    print(f"   Valor final: {memory_gate_final:.6f}")
    print(f"   Activaci√≥n: {memory_gate_activated*100:.2f}%")
    
    # Verificar si cumple expectativas
    if improvement >= 25.0:
        print("\n‚úÖ ¬°√âXITO! La Golden Seed produjo mejora ‚â•25% (esperado ~30%)")
    elif improvement >= 15.0:
        print("\n‚ö†Ô∏è RESULTADO ACEPTABLE: Mejora ‚â•15% (algo por debajo del 30% esperado)")
    elif improvement > 0:
        print("\n‚ö†Ô∏è RESULTADO SUB√ìPTIMO: Mejora positiva pero menor al esperado")
    else:
        print("\n‚ùå RESULTADO INESPERADO: No hubo mejora (verificar configuraci√≥n)")
    
    # ==========================================================================
    # GUARDAR RESULTADOS
    # ==========================================================================
    print("\n" + "="*80)
    print("üíæ GUARDANDO RESULTADOS")
    print("="*80)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Guardar modelos
    torch.save({
        'model_state_dict': model_golden.state_dict(),
        'memory_gate_value': memory_gate_final,
        'final_loss': loss_golden_final,
        'improvement': improvement,
        'epochs': EPOCHS,
        'config': config
    }, f"../models/golden_seed_trained_{timestamp}.pt")
    
    print(f"‚úÖ Modelo Golden Seed entrenado guardado")
    
    # Guardar historial
    results = {
        'timestamp': timestamp,
        'experiment': 'Golden Seed 2 vs Baseline',
        'results': {
            'golden_seed_loss': loss_golden_final,
            'baseline_loss': loss_baseline_final,
            'improvement_percentage': improvement,
            'memory_gate_final': memory_gate_final,
            'memory_gate_activated': memory_gate_activated
        },
        'config': config,
        'epochs': EPOCHS,
        'loss_history': {
            'golden_seed': history_golden,
            'baseline': history_baseline
        }
    }
    
    results_path = f"../models/golden_seed_results_{timestamp}.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"‚úÖ Resultados guardados en {results_path}")
    
    # ==========================================================================
    # PRUEBA CUALITATIVA
    # ==========================================================================
    print("\n" + "="*80)
    print("üéØ PRUEBA CUALITATIVA")
    print("="*80)
    
    with torch.no_grad():
        test_in, test_out = get_batch(1)
        test_in = test_in.to(DEVICE)
        
        print(f"\nInput: {[idx_to_char[i.item()] for i in test_in[0] if i.item()!=0]}")
        print(f"Target: {[idx_to_char[i.item()] for i in test_out[0] if i.item()!=0 and i.item() in idx_to_char]}")
        
        out_base, _ = model_baseline(test_in)
        pred_base = torch.argmax(out_base, dim=2)
        print(f"Baseline pred: {[idx_to_char[i.item()] for i in pred_base[0] if i.item() in idx_to_char]}")
        
        out_golden, _ = model_golden(test_in)
        pred_golden = torch.argmax(out_golden, dim=2)
        print(f"Golden pred:   {[idx_to_char[i.item()] for i in pred_golden[0] if i.item() in idx_to_char]}")
    
    print("\n" + "="*80)
    print("üéâ ENTRENAMIENTO COMPLETADO")
    print("="*80)
    print(f"\nüí° La Golden Seed garantiz√≥: {improvement:.2f}% de mejora")
    print("‚úÖ Inicializaci√≥n reproducible lista para producci√≥n")


if __name__ == "__main__":
    main()
