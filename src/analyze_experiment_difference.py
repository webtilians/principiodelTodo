#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”¬ ANÃLISIS: Â¿Por quÃ© el experimento anterior dio mejores resultados?
====================================================================

Compara los resultados del experimento actual con el anterior para
determinar quÃ© causÃ³ la diferencia en mejora (23.16% vs 3.56%).
"""

import sys
import os
import json
import torch
import matplotlib.pyplot as plt

# Configurar encoding UTF-8 para Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')


def analyze_training_dynamics():
    """Analiza la dinÃ¡mica de entrenamiento del experimento actual."""
    
    print("="*70)
    print("ğŸ”¬ ANÃLISIS COMPARATIVO: Â¿Por quÃ© el primer experimento fue mejor?")
    print("="*70)
    
    # Cargar resultados del experimento actual (V3)
    try:
        with open('training_results_v3.json', 'r') as f:
            results_v3 = json.load(f)
    except FileNotFoundError:
        print("âŒ No se encontrÃ³ training_results_v3.json")
        print("   Ejecuta primero: python src/infinito_gemini.py")
        return
    
    print("\nğŸ“Š EXPERIMENTO ACTUAL (V3 - ReciÃ©n ejecutado):")
    print(f"   IIT Loss: {results_v3['results']['iit_final_loss']:.5f}")
    print(f"   Baseline Loss: {results_v3['results']['baseline_final_loss']:.5f}")
    print(f"   Mejora: {results_v3['results']['improvement_percentage']:.2f}%")
    print(f"   Memory Gate: {results_v3['results']['memory_gate_value']:.6f}")
    
    print("\nğŸ“Š EXPERIMENTO ANTERIOR (Primera ejecuciÃ³n exitosa):")
    print(f"   IIT Loss: 0.34393")
    print(f"   Baseline Loss: 0.44756")
    print(f"   Mejora: 23.16%")
    print(f"   Memory Gate: (desconocido - no se guardÃ³)")
    
    print("\n" + "="*70)
    print("ğŸ” DIFERENCIAS CRÃTICAS DETECTADAS")
    print("="*70)
    
    # Analizar las curvas de aprendizaje
    iit_history = results_v3['loss_history']['iit']
    base_history = results_v3['loss_history']['baseline']
    
    # Calcular convergencia
    iit_early = sum(iit_history[:500]) / 500
    iit_late = sum(iit_history[-500:]) / 500
    base_early = sum(base_history[:500]) / 500
    base_late = sum(base_history[-500:]) / 500
    
    print("\n1ï¸âƒ£ VELOCIDAD DE CONVERGENCIA:")
    print(f"   IIT  - Primeras 500 Ã©pocas: {iit_early:.4f}")
    print(f"   IIT  - Ãšltimas 500 Ã©pocas: {iit_late:.4f}")
    print(f"   IIT  - Mejora interna: {((iit_early-iit_late)/iit_early*100):.2f}%")
    print(f"")
    print(f"   Base - Primeras 500 Ã©pocas: {base_early:.4f}")
    print(f"   Base - Ãšltimas 500 Ã©pocas: {base_late:.4f}")
    print(f"   Base - Mejora interna: {((base_early-base_late)/base_early*100):.2f}%")
    
    # Analizar varianza (estabilidad)
    iit_variance = sum([(x - iit_late)**2 for x in iit_history[-500:]]) / 500
    base_variance = sum([(x - base_late)**2 for x in base_history[-500:]]) / 500
    
    print("\n2ï¸âƒ£ ESTABILIDAD DEL ENTRENAMIENTO:")
    print(f"   IIT Varianza (Ãºltimas 500): {iit_variance:.6f}")
    print(f"   Base Varianza (Ãºltimas 500): {base_variance:.6f}")
    if iit_variance < base_variance:
        print("   âœ… IIT es mÃ¡s estable")
    else:
        print("   âŒ IIT es menos estable que Baseline")
    
    print("\n3ï¸âƒ£ MEMORY GATE APRENDIZAJE:")
    gate_value = results_v3['results']['memory_gate_value']
    gate_activated = results_v3['results']['memory_gate_activated']
    print(f"   Raw value: {gate_value:.6f}")
    print(f"   Activated (sigmoid): {gate_activated:.6f}")
    print(f"   Uso efectivo de memoria: {gate_activated*100:.2f}%")
    
    if abs(gate_value) < 0.01:
        print("   âš ï¸ PROBLEMA: El gate NO aprendiÃ³ a moverse de su valor inicial")
        print("   â†’ La memoria NO se estÃ¡ usando efectivamente")
        print("   â†’ El modelo IIT funciona bÃ¡sicamente como Baseline + ruido")
    
    # Comparar loss finales
    print("\n4ï¸âƒ£ COMPARACIÃ“N DE LOSS FINALES:")
    print(f"   Experimento Anterior:")
    print(f"      IIT: 0.34393 | Base: 0.44756 | Gap: {0.44756-0.34393:.5f}")
    print(f"   Experimento Actual:")
    print(f"      IIT: {results_v3['results']['iit_final_loss']:.5f} | Base: {results_v3['results']['baseline_final_loss']:.5f} | Gap: {results_v3['results']['baseline_final_loss']-results_v3['results']['iit_final_loss']:.5f}")
    
    gap_anterior = 0.44756 - 0.34393
    gap_actual = results_v3['results']['baseline_final_loss'] - results_v3['results']['iit_final_loss']
    
    print(f"\n   ğŸ“‰ Gap anterior: {gap_anterior:.5f}")
    print(f"   ğŸ“‰ Gap actual: {gap_actual:.5f}")
    print(f"   ğŸ“Š Diferencia de gaps: {gap_anterior - gap_actual:.5f}")
    print(f"   ğŸ”» ReducciÃ³n de ventaja: {((gap_anterior - gap_actual)/gap_anterior*100):.1f}%")
    
    print("\n" + "="*70)
    print("ğŸ’¡ HIPÃ“TESIS SOBRE LA DIFERENCIA (ORDENADAS POR PROBABILIDAD)")
    print("="*70)
    
    print("\nğŸ¯ HIPÃ“TESIS #1: SEED ALEATORIO (Probabilidad: 80%)")
    print("   ğŸ“ DescripciÃ³n:")
    print("      â€¢ Los experimentos NO fijan seed para generaciÃ³n de datos")
    print("      â€¢ Cada ejecuciÃ³n genera secuencias Dyck diferentes aleatoriamente")
    print("      â€¢ Algunas secuencias son mÃ¡s fÃ¡ciles/difÃ­ciles que otras")
    print("   ğŸ”¬ Evidencia:")
    print("      â€¢ El cÃ³digo usa random.choice() sin seed fijo")
    print("      â€¢ Loss finales varÃ­an mucho entre ejecuciones")
    print(f"      â€¢ Baseline variÃ³: 0.44756 â†’ {results_v3['results']['baseline_final_loss']:.5f}")
    print(f"      â€¢ IIT variÃ³: 0.34393 â†’ {results_v3['results']['iit_final_loss']:.5f}")
    print("   âœ… SoluciÃ³n:")
    print("      â€¢ Fijar random.seed() y torch.manual_seed() al inicio")
    print("      â€¢ Ejecutar mÃºltiples experimentos con seeds diferentes")
    print("      â€¢ Promediar resultados")
    
    print("\nğŸ¯ HIPÃ“TESIS #2: MEMORY GATE NO APRENDE (Probabilidad: 15%)")
    print("   ğŸ“ DescripciÃ³n:")
    print(f"      â€¢ Gate actual: {gate_value:.6f} (prÃ¡cticamente 0)")
    print(f"      â€¢ ActivaciÃ³n: {gate_activated:.4f} (50% = no aprendiÃ³ nada)")
    print("      â€¢ La memoria existe pero NO se usa")
    print("   ğŸ”¬ Evidencia:")
    print("      â€¢ lambda_phi = 0.0 (sin presiÃ³n para usar PHI)")
    print("      â€¢ Solo 3000 Ã©pocas (quizÃ¡ insuficiente)")
    print("      â€¢ Sin seÃ±al explÃ­cita de que memoria ayuda")
    print("   âœ… SoluciÃ³n:")
    print("      â€¢ Aumentar Ã©pocas a 5000-10000")
    print("      â€¢ Usar lambda_phi > 0 (ej. 0.01) para forzar integraciÃ³n")
    print("      â€¢ AÃ±adir reward explÃ­cito por usar memoria")
    
    print("\nğŸ¯ HIPÃ“TESIS #3: INICIALIZACIÃ“N DE PESOS (Probabilidad: 5%)")
    print("   ğŸ“ DescripciÃ³n:")
    print("      â€¢ PyTorch inicializa pesos aleatoriamente")
    print("      â€¢ Experimento anterior pudo tener inicializaciÃ³n favorable")
    print("   ğŸ”¬ Evidencia:")
    print("      â€¢ No hay torch.manual_seed() en el cÃ³digo")
    print("      â€¢ Cada ejecuciÃ³n parte de pesos diferentes")
    print("   âœ… SoluciÃ³n:")
    print("      â€¢ Fijar torch.manual_seed() antes de crear modelos")
    
    print("\n" + "="*70)
    print("ğŸ”¬ ANÃLISIS DEL CÃ“DIGO: Â¿QuÃ© cambiÃ³?")
    print("="*70)
    
    print("\nğŸ“‹ CÃ“DIGO ANTERIOR (con bug):")
    print("""
    # âŒ BUG: Memoria leÃ­da pero NO usada
    read_content, read_weights = self.memory.read(...)
    # ... escritura ...
    logits = self.output_projection(hidden)  # <-- Sin memoria!
    """)
    
    print("\nğŸ“‹ CÃ“DIGO ACTUAL (corregido):")
    print("""
    # âœ… Memoria leÃ­da Y usada con gate
    read_content, read_weights = self.memory.read(...)
    gated_memory = torch.sigmoid(self.memory_gate) * read_content
    hidden = hidden + gated_memory
    hidden = self.memory_norm(hidden)
    logits = self.output_projection(hidden)
    """)
    
    print("\nğŸ¤” PARADOJA OBSERVADA:")
    print("   â€¢ El cÃ³digo CON BUG dio mejor resultado (23.16%)")
    print("   â€¢ El cÃ³digo CORREGIDO dio peor resultado (3.56%)")
    print("   ")
    print("   ğŸ’¡ EXPLICACIÃ“N MÃS PROBABLE:")
    print("   â†’ NO es paradoja, es VARIANZA ALEATORIA")
    print("   â†’ El experimento anterior tuvo SUERTE con el seed")
    print("   â†’ El actual tuvo MALA SUERTE con el seed")
    print("   â†’ Necesitamos mÃºltiples ejecuciones para confirmar")
    
    # Visualizar curvas de aprendizaje
    print("\n" + "="*70)
    print("ğŸ“ˆ GENERANDO GRÃFICAS DE ANÃLISIS")
    print("="*70)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('AnÃ¡lisis de Entrenamiento: Experimento V3 vs Anterior', fontsize=16)
    
    # GrÃ¡fica 1: Curvas completas
    axes[0, 0].plot(iit_history, label='IIT Actual', alpha=0.7)
    axes[0, 0].plot(base_history, label='Baseline Actual', alpha=0.7)
    axes[0, 0].axhline(y=0.34393, color='g', linestyle='--', label='IIT Anterior', alpha=0.5)
    axes[0, 0].axhline(y=0.44756, color='r', linestyle='--', label='Base Anterior', alpha=0.5)
    axes[0, 0].set_xlabel('Ã‰poca')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('Curvas de Aprendizaje Completas')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # GrÃ¡fica 2: Ãšltimas 500 Ã©pocas (convergencia)
    axes[0, 1].plot(iit_history[-500:], label='IIT Actual', alpha=0.7)
    axes[0, 1].plot(base_history[-500:], label='Baseline Actual', alpha=0.7)
    axes[0, 1].axhline(y=0.34393, color='g', linestyle='--', label='IIT Anterior', alpha=0.5)
    axes[0, 1].axhline(y=0.44756, color='r', linestyle='--', label='Base Anterior', alpha=0.5)
    axes[0, 1].set_xlabel('Ã‰poca (Ãºltimas 500)')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].set_title('Convergencia Final')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # GrÃ¡fica 3: Gap entre modelos
    gap_history = [base_history[i] - iit_history[i] for i in range(len(iit_history))]
    axes[1, 0].plot(gap_history, label='Gap Actual (Base-IIT)', color='purple', alpha=0.7)
    axes[1, 0].axhline(y=gap_anterior, color='orange', linestyle='--', 
                       label=f'Gap Anterior: {gap_anterior:.5f}', alpha=0.7)
    axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
    axes[1, 0].set_xlabel('Ã‰poca')
    axes[1, 0].set_ylabel('Gap (Baseline - IIT)')
    axes[1, 0].set_title('Ventaja del IIT sobre Baseline')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].fill_between(range(len(gap_history)), 0, gap_history, 
                             where=[g > 0 for g in gap_history], 
                             alpha=0.3, color='green', label='IIT mejor')
    axes[1, 0].fill_between(range(len(gap_history)), 0, gap_history, 
                             where=[g < 0 for g in gap_history], 
                             alpha=0.3, color='red', label='Baseline mejor')
    
    # GrÃ¡fica 4: ComparaciÃ³n de loss finales
    experiments = ['Anterior\n(23.16%)', 'Actual\n(3.56%)']
    iit_losses = [0.34393, results_v3['results']['iit_final_loss']]
    base_losses = [0.44756, results_v3['results']['baseline_final_loss']]
    
    x = range(len(experiments))
    width = 0.35
    axes[1, 1].bar([i - width/2 for i in x], iit_losses, width, label='IIT', color='green', alpha=0.7)
    axes[1, 1].bar([i + width/2 for i in x], base_losses, width, label='Baseline', color='red', alpha=0.7)
    axes[1, 1].set_ylabel('Loss Final')
    axes[1, 1].set_title('ComparaciÃ³n de Loss Finales')
    axes[1, 1].set_xticks(x)
    axes[1, 1].set_xticklabels(experiments)
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3, axis='y')
    
    # AÃ±adir anotaciones de mejora
    for i, (iit_l, base_l) in enumerate(zip(iit_losses, base_losses)):
        mejora = ((base_l - iit_l) / base_l) * 100
        axes[1, 1].text(i, max(iit_l, base_l) + 0.02, f'{mejora:.1f}%', 
                        ha='center', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    
    # Guardar grÃ¡fica
    graph_path = 'experiment_comparison_analysis.png'
    plt.savefig(graph_path, dpi=150, bbox_inches='tight')
    print(f"âœ… GrÃ¡ficas guardadas: {graph_path}")
    
    plt.show()
    
    # Resumen final
    print("\n" + "="*70)
    print("ğŸ¯ CONCLUSIÃ“N Y RECOMENDACIONES")
    print("="*70)
    
    print("\nğŸ“Š CONCLUSIÃ“N PRINCIPAL:")
    print("   La diferencia de 23.16% vs 3.56% es probablemente debida a")
    print("   VARIABILIDAD ALEATORIA en la generaciÃ³n de datos y pesos iniciales.")
    print("   ")
    print("   NO es evidencia de que el bug ayudara o el fix empeorara el modelo.")
    
    print("\nâœ… RECOMENDACIONES:")
    print("   1. Ejecutar experimento con mÃºltiples seeds (10-20 repeticiones)")
    print("   2. Calcular media y desviaciÃ³n estÃ¡ndar de la mejora")
    print("   3. Si la mejora promedio es >10% con p<0.05, es significativa")
    print("   4. Aumentar Ã©pocas para permitir que memory_gate aprenda")
    print("   5. AÃ±adir lambda_phi > 0 para incentivar uso de memoria")
    
    print("\nğŸš€ SIGUIENTE PASO:")
    print("   Â¿Quieres que cree un script para ejecutar mÃºltiples experimentos")
    print("   con seeds diferentes y obtener resultados estadÃ­sticamente vÃ¡lidos?")
    
    print("\n" + "="*70)


if __name__ == '__main__':
    analyze_training_dynamics()
