#!/usr/bin/env python3
"""
ðŸ›¡ï¸ SISTEMA ANTI-ALUCINACIÃ“N usando INFINITO Memory Patterns
============================================================

Experimento: Usar embeddings TF-IDF para prevenir que un sistema
responda con informaciÃ³n inventada (alucinaciones).

FILOSOFÃA:
1. Si la pregunta ya fue respondida y verificada â†’ usar memoria (100% seguro)
2. Si es similar a algo conocido â†’ advertir nivel de certeza
3. Si es completamente nueva â†’ marcar como "no verificado"

MÃ‰TRICAS DE SEGURIDAD:
- Similitud >95% â†’ VERIFICADO (98% seguro)
- Similitud 85-95% â†’ PROBABLE (85% seguro)
- Similitud 70-85% â†’ INCIERTO (70% seguro)
- Similitud <70% â†’ DESCONOCIDO (rechazar)
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import json
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, Tuple, Optional


class AntiHallucinationGuard:
    """Sistema de protecciÃ³n anti-alucinaciÃ³n basado en memoria de patrones"""
    
    def __init__(self, memory_file='anti_hallucination_memory.json'):
        """
        Inicializar el sistema de protecciÃ³n
        
        Args:
            memory_file: Archivo JSON para persistencia
        """
        self.memory_file = Path(memory_file)
        
        # Memoria de patrones: {pattern_hash: pattern_data}
        self.patterns = {}
        
        # Conocimiento verificado: {pattern_hash: verified_data}
        self.verified_knowledge = {}
        
        # Umbrales de confianza
        self.THRESHOLD_VERIFIED = 0.95    # 98% seguro
        self.THRESHOLD_PROBABLE = 0.85    # 85% seguro
        self.THRESHOLD_UNCERTAIN = 0.70   # 70% seguro
        
        # EstadÃ­sticas
        self.stats = {
            'total_queries': 0,
            'from_memory': 0,
            'from_llm': 0,
            'rejected_uncertain': 0,
            'hallucinations_prevented': 0
        }
        
        # Cargar memoria existente
        self.load_memory()
    
    def _text_to_embedding(self, text: str) -> np.ndarray:
        """
        Convertir texto a embedding TF-IDF simplificado
        
        Para el demo, usamos una versiÃ³n simplificada.
        En producciÃ³n, usar el SemanticTextEmbedder completo.
        """
        # Tokenizar y crear vector simple
        words = text.lower().split()
        
        # Vocabulario base (expandible)
        vocab = set()
        for word in words:
            vocab.add(word)
        
        # Crear vector binario (presencia de palabras)
        vocab_list = sorted(vocab)
        vector = np.array([1.0 if w in words else 0.0 for w in vocab_list])
        
        # Normalizar L2
        norm = np.linalg.norm(vector)
        if norm > 1e-10:
            vector = vector / norm
        
        return vector
    
    def _compute_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calcular similitud coseno entre dos vectores"""
        # Asegurar misma dimensiÃ³n (padding con ceros)
        max_len = max(len(vec1), len(vec2))
        v1 = np.pad(vec1, (0, max_len - len(vec1)))
        v2 = np.pad(vec2, (0, max_len - len(vec2)))
        
        # Similitud coseno
        dot_product = np.dot(v1, v2)
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)
        
        if norm1 < 1e-10 or norm2 < 1e-10:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _find_similar_pattern(self, embedding: np.ndarray) -> Tuple[Optional[str], float]:
        """
        Buscar patrÃ³n similar en memoria
        
        Returns:
            (pattern_hash, similarity) o (None, 0.0)
        """
        best_match = None
        best_similarity = 0.0
        
        for pattern_hash, pattern_data in self.patterns.items():
            stored_embedding = np.array(pattern_data['embedding'])
            similarity = self._compute_similarity(embedding, stored_embedding)
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = pattern_hash
        
        return best_match, best_similarity
    
    def ask(self, 
            question: str, 
            llm_function=None, 
            verification_source=None) -> Dict:
        """
        Procesar pregunta con protecciÃ³n anti-alucinaciÃ³n
        
        Args:
            question: Pregunta del usuario
            llm_function: FunciÃ³n que llama al LLM (opcional)
            verification_source: Fuente para validar respuesta (opcional)
            
        Returns:
            {
                'answer': str,
                'confidence': float,
                'verified': bool,
                'source': str,
                'security_level': str
            }
        """
        self.stats['total_queries'] += 1
        
        # 1. Convertir pregunta a embedding
        question_embedding = self._text_to_embedding(question)
        
        # 2. Buscar en memoria
        match_hash, similarity = self._find_similar_pattern(question_embedding)
        
        # 3. Evaluar nivel de confianza
        if similarity >= self.THRESHOLD_VERIFIED and match_hash:
            # âœ… VERIFICADO (98% seguro)
            verified_data = self.verified_knowledge.get(match_hash)
            if verified_data and verified_data['verified']:
                self.stats['from_memory'] += 1
                return {
                    'answer': verified_data['answer'],
                    'confidence': 0.98,
                    'verified': True,
                    'source': 'memory_verified',
                    'security_level': 'HIGH',
                    'original_question': verified_data['question'],
                    'similarity': similarity
                }
        
        elif similarity >= self.THRESHOLD_PROBABLE and match_hash:
            # âš ï¸ PROBABLE (85% seguro)
            verified_data = self.verified_knowledge.get(match_hash)
            if verified_data:
                self.stats['from_memory'] += 1
                return {
                    'answer': f"[Pregunta similar encontrada]\nOriginal: '{verified_data['question']}'\n\n{verified_data['answer']}",
                    'confidence': 0.85,
                    'verified': verified_data['verified'],
                    'source': 'memory_similar',
                    'security_level': 'MEDIUM',
                    'similarity': similarity
                }
        
        elif similarity >= self.THRESHOLD_UNCERTAIN and match_hash:
            # âš ï¸ INCIERTO (70% seguro)
            # Puede ser relacionado, pero no suficientemente similar
            pass  # Continuar a LLM si estÃ¡ disponible
        
        # 4. Pregunta nueva â†’ consultar LLM
        if llm_function:
            llm_answer = llm_function(question)
            
            # Verificar si es una alucinaciÃ³n
            is_verified = False
            if verification_source:
                is_verified = verification_source(question, llm_answer)
                if not is_verified:
                    self.stats['hallucinations_prevented'] += 1
                    return {
                        'answer': "âš ï¸ No puedo verificar esta informaciÃ³n. Por favor consulta fuentes especializadas.",
                        'confidence': 0.30,
                        'verified': False,
                        'source': 'llm_rejected',
                        'security_level': 'LOW'
                    }
            
            # Guardar en memoria
            pattern_hash = self._store_pattern(question, question_embedding, llm_answer, is_verified)
            
            self.stats['from_llm'] += 1
            
            return {
                'answer': llm_answer if is_verified else f"{llm_answer}\n\nâš ï¸ Nota: Esta respuesta no ha sido verificada.",
                'confidence': 0.75 if is_verified else 0.50,
                'verified': is_verified,
                'source': 'llm_new',
                'security_level': 'MEDIUM' if is_verified else 'LOW'
            }
        
        # 5. Sin LLM ni memoria â†’ respuesta honesta
        self.stats['rejected_uncertain'] += 1
        return {
            'answer': "No tengo informaciÃ³n sobre esto. Por favor verifica con fuentes confiables.",
            'confidence': 0.0,
            'verified': False,
            'source': 'unknown',
            'security_level': 'NONE'
        }
    
    def _store_pattern(self, question: str, embedding: np.ndarray, answer: str, verified: bool) -> str:
        """Guardar patrÃ³n en memoria"""
        pattern_hash = f"pattern_{len(self.patterns):04d}"
        
        self.patterns[pattern_hash] = {
            'embedding': embedding.tolist(),
            'question': question,
            'timestamp': datetime.now().isoformat()
        }
        
        self.verified_knowledge[pattern_hash] = {
            'question': question,
            'answer': answer,
            'verified': verified,
            'timestamp': datetime.now().isoformat()
        }
        
        self.save_memory()
        return pattern_hash
    
    def verify_answer(self, question: str, is_correct: bool, correct_answer: str = None):
        """Verificar manualmente una respuesta existente"""
        question_embedding = self._text_to_embedding(question)
        match_hash, similarity = self._find_similar_pattern(question_embedding)
        
        if similarity > 0.95 and match_hash:
            self.verified_knowledge[match_hash]['verified'] = is_correct
            if correct_answer:
                self.verified_knowledge[match_hash]['answer'] = correct_answer
            self.save_memory()
            return True
        return False
    
    def get_stats(self) -> Dict:
        """Obtener estadÃ­sticas del sistema"""
        return {
            **self.stats,
            'total_patterns': len(self.patterns),
            'verified_patterns': sum(1 for v in self.verified_knowledge.values() if v['verified']),
            'prevention_rate': f"{(self.stats['hallucinations_prevented'] / max(1, self.stats['total_queries']) * 100):.1f}%"
        }
    
    def save_memory(self):
        """Guardar memoria a disco"""
        data = {
            'patterns': self.patterns,
            'verified_knowledge': self.verified_knowledge,
            'stats': self.stats
        }
        with open(self.memory_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def load_memory(self):
        """Cargar memoria desde disco"""
        if self.memory_file.exists():
            try:
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.patterns = data.get('patterns', {})
                self.verified_knowledge = data.get('verified_knowledge', {})
                self.stats = data.get('stats', self.stats)
                print(f"âœ… Memoria cargada: {len(self.patterns)} patrones")
            except Exception as e:
                print(f"âš ï¸ Error cargando memoria: {e}")


# ========== SIMULACIÃ“N DE LLM ==========

def mock_llm(question: str) -> str:
    """
    LLM simulado con conocimiento correcto e incorrecto
    
    Simula un LLM que:
    - Tiene conocimiento real sobre algunos temas
    - Alucina sobre temas que no conoce
    """
    q_lower = question.lower()
    
    # Base de conocimiento CORRECTO
    knowledge = {
        'francia': "La capital de Francia es ParÃ­s, una de las ciudades mÃ¡s visitadas del mundo.",
        'espaÃ±a': "La capital de EspaÃ±a es Madrid, situada en el centro del paÃ­s.",
        'alemania': "La capital de Alemania es BerlÃ­n, que fue reunificada en 1990.",
        'bombilla': "Thomas Edison inventÃ³ la bombilla elÃ©ctrica prÃ¡ctica en 1879.",
        'penicilina': "La penicilina fue descubierta por Alexander Fleming en 1928.",
        'gravedad': "La ley de la gravedad fue formulada por Isaac Newton.",
    }
    
    # Buscar conocimiento
    for key, answer in knowledge.items():
        if key in q_lower:
            return answer
    
    # âŒ ALUCINACIÃ“N: Inventar informaciÃ³n
    # Simula el comportamiento de un LLM que "inventa" cuando no sabe
    hallucinations = [
        f"SegÃºn investigaciones recientes, {question.lower()} estÃ¡ relacionado con descubrimientos del aÃ±o 2024.",
        f"Los expertos coinciden en que {question.lower()} fue establecido en el siglo XIX.",
        f"Estudios demuestran que {question.lower()} tiene una correlaciÃ³n del 87% con fenÃ³menos cuÃ¡nticos.",
    ]
    
    import random
    return random.choice(hallucinations)


def mock_verifier(question: str, answer: str) -> bool:
    """
    Verificador simulado
    
    Simula una base de datos de hechos verificados.
    En producciÃ³n, esto serÃ­a una API, base de datos, o modelo de fact-checking.
    """
    verified_facts = {
        'francia': ['parÃ­s', 'paris'],
        'espaÃ±a': ['madrid'],
        'alemania': ['berlÃ­n', 'berlin'],
        'bombilla': ['edison', '1879'],
        'penicilina': ['fleming', '1928'],
        'gravedad': ['newton'],
    }
    
    answer_lower = answer.lower()
    question_lower = question.lower()
    
    # Verificar si la respuesta contiene hechos correctos
    for topic, facts in verified_facts.items():
        if topic in question_lower:
            # La respuesta debe contener al menos uno de los hechos verificados
            return any(fact in answer_lower for fact in facts)
    
    # Si no estÃ¡ en la base de conocimiento â†’ no verificado
    return False


# ========== DEMO INTERACTIVO ==========

def run_experiment():
    """Ejecutar experimento de anti-alucinaciÃ³n"""
    
    print("=" * 70)
    print("ðŸ›¡ï¸  EXPERIMENTO: SISTEMA ANTI-ALUCINACIÃ“N")
    print("=" * 70)
    print("\nObjetivo: Prevenir que el sistema responda con informaciÃ³n inventada")
    print("\nMecanismo:")
    print("  1. Si la pregunta ya fue respondida â†’ usar memoria (100% seguro)")
    print("  2. Si es similar â†’ advertir nivel de certeza")
    print("  3. Si es nueva â†’ validar con fuente antes de guardar")
    print("=" * 70)
    
    # Inicializar sistema
    guard = AntiHallucinationGuard()
    
    # Casos de prueba
    test_cases = [
        {
            'question': 'Â¿CuÃ¡l es la capital de Francia?',
            'expected': 'ParÃ­s',
            'category': 'Conocimiento verificable'
        },
        {
            'question': 'Â¿Capital de Francia?',
            'expected': 'ParÃ­s (variaciÃ³n de pregunta)',
            'category': 'VariaciÃ³n sintÃ¡ctica'
        },
        {
            'question': 'Â¿CuÃ¡l es la capital de EspaÃ±a?',
            'expected': 'Madrid',
            'category': 'Conocimiento relacionado'
        },
        {
            'question': 'Â¿QuiÃ©n inventÃ³ la bombilla?',
            'expected': 'Edison',
            'category': 'Conocimiento verificable'
        },
        {
            'question': 'Â¿CuÃ¡l es la capital de Atlantis?',
            'expected': 'AlucinaciÃ³n detectada',
            'category': 'Pregunta sobre ficciÃ³n'
        },
        {
            'question': 'Â¿CuÃ¡ndo se descubriÃ³ el elemento Unobtainium?',
            'expected': 'AlucinaciÃ³n detectada',
            'category': 'Pregunta sobre elemento ficticio'
        },
    ]
    
    print(f"\nðŸ§ª Ejecutando {len(test_cases)} casos de prueba...\n")
    
    results = []
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{'â”€' * 70}")
        print(f"CASO {i}: {case['category']}")
        print(f"{'â”€' * 70}")
        print(f"â“ Pregunta: {case['question']}")
        
        # Procesar con el sistema
        result = guard.ask(
            case['question'],
            llm_function=mock_llm,
            verification_source=mock_verifier
        )
        
        # Mostrar resultado
        security_emoji = {
            'HIGH': 'âœ…',
            'MEDIUM': 'âš ï¸',
            'LOW': 'âŒ',
            'NONE': 'ðŸš«'
        }
        
        emoji = security_emoji.get(result['security_level'], 'â“')
        
        print(f"\n{emoji} Respuesta ({result['source']}):")
        print(f"   {result['answer']}")
        print(f"\nðŸ“Š MÃ©tricas:")
        print(f"   Confianza: {result['confidence']*100:.0f}%")
        print(f"   Verificado: {'SÃ­' if result['verified'] else 'No'}")
        print(f"   Nivel de seguridad: {result['security_level']}")
        
        if 'similarity' in result:
            print(f"   Similitud con memoria: {result['similarity']*100:.1f}%")
        
        # Evaluar resultado
        is_correct = (
            (result['verified'] and case['expected'] != 'AlucinaciÃ³n detectada') or
            (not result['verified'] and result['source'] == 'llm_rejected' and case['expected'] == 'AlucinaciÃ³n detectada')
        )
        
        results.append({
            'case': case['category'],
            'question': case['question'],
            'correct': is_correct,
            'security_level': result['security_level'],
            'source': result['source']
        })
    
    # Resumen
    print(f"\n{'=' * 70}")
    print("ðŸ“Š RESUMEN DEL EXPERIMENTO")
    print(f"{'=' * 70}")
    
    correct_count = sum(1 for r in results if r['correct'])
    total = len(results)
    
    print(f"\nâœ… Casos correctos: {correct_count}/{total} ({correct_count/total*100:.0f}%)")
    
    print(f"\nðŸ“‹ Detalle por caso:")
    for i, r in enumerate(results, 1):
        status = "âœ…" if r['correct'] else "âŒ"
        print(f"   {status} {i}. {r['case']}")
        print(f"      Pregunta: {r['question']}")
        print(f"      Fuente: {r['source']} | Seguridad: {r['security_level']}")
    
    # EstadÃ­sticas del sistema
    stats = guard.get_stats()
    
    print(f"\n{'=' * 70}")
    print("ðŸ“ˆ ESTADÃSTICAS DEL SISTEMA")
    print(f"{'=' * 70}")
    print(f"   Total consultas: {stats['total_queries']}")
    print(f"   Desde memoria: {stats['from_memory']}")
    print(f"   Desde LLM: {stats['from_llm']}")
    print(f"   Rechazadas (inciertas): {stats['rejected_uncertain']}")
    print(f"   Alucinaciones prevenidas: {stats['hallucinations_prevented']}")
    print(f"   Tasa de prevenciÃ³n: {stats['prevention_rate']}")
    print(f"   Patrones en memoria: {stats['total_patterns']}")
    print(f"   Patrones verificados: {stats['verified_patterns']}")
    
    # ConclusiÃ³n
    print(f"\n{'=' * 70}")
    print("ðŸ’¡ CONCLUSIONES")
    print(f"{'=' * 70}")
    
    if correct_count / total >= 0.8:
        print("âœ… El sistema FUNCIONA correctamente")
        print("   - Detecta preguntas conocidas")
        print("   - Previene alucinaciones sobre temas desconocidos")
        print("   - Mantiene memoria de respuestas verificadas")
    else:
        print("âš ï¸  El sistema necesita ajustes")
    
    prevention_rate = stats['hallucinations_prevented'] / max(1, stats['from_llm']) * 100
    print(f"\nðŸ›¡ï¸  Efectividad anti-alucinaciÃ³n: {prevention_rate:.0f}%")
    
    print(f"\n{'=' * 70}")


def run_interactive_mode():
    """Modo interactivo para probar el sistema"""
    
    print("\n" + "=" * 70)
    print("ðŸŽ® MODO INTERACTIVO")
    print("=" * 70)
    print("\nComandos:")
    print("  - Escribe una pregunta")
    print("  - 'stats'  - Ver estadÃ­sticas")
    print("  - 'exit'   - Salir")
    print("=" * 70)
    
    guard = AntiHallucinationGuard()
    
    while True:
        try:
            user_input = input("\nðŸ’¬ Pregunta: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() == 'exit':
                print("ðŸ‘‹ Â¡Hasta luego!")
                break
            
            if user_input.lower() == 'stats':
                stats = guard.get_stats()
                print("\nðŸ“Š EstadÃ­sticas:")
                for key, value in stats.items():
                    print(f"   {key}: {value}")
                continue
            
            # Procesar pregunta
            result = guard.ask(
                user_input,
                llm_function=mock_llm,
                verification_source=mock_verifier
            )
            
            # Mostrar resultado
            security_emoji = {
                'HIGH': 'âœ…',
                'MEDIUM': 'âš ï¸',
                'LOW': 'âŒ',
                'NONE': 'ðŸš«'
            }
            
            emoji = security_emoji.get(result['security_level'], 'â“')
            
            print(f"\n{emoji} Respuesta:")
            print(f"   {result['answer']}")
            print(f"\n   Confianza: {result['confidence']*100:.0f}% | Seguridad: {result['security_level']}")
            
        except KeyboardInterrupt:
            print("\n\nðŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--interactive':
        run_interactive_mode()
    else:
        run_experiment()
