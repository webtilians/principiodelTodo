"""
üåô DEMO: Sistema de Consolidaci√≥n de Memoria
=============================================

Este script demuestra c√≥mo funciona el aprendizaje continuo
con LoRA + Replay Buffer.

Simula:
1. A√±adir interacciones al buffer
2. Entrenar los adapters (consolidaci√≥n)
3. Ver c√≥mo mejora la predicci√≥n de importancia
"""

import sys
import os
sys.path.insert(0, 'src')

import torch
import numpy as np
from datetime import datetime

from neural_memory import NeuralMemoryManager, ReplayBuffer
from lora_adapter import LoRAAdapter

print("=" * 70)
print("üåô DEMO: CONSOLIDACI√ìN DE MEMORIA NEURONAL")
print("=" * 70)

# =============================================================================
# 1. CREAR EL NEURAL MEMORY MANAGER
# =============================================================================
print("\nüì¶ PASO 1: Creando Neural Memory Manager...")

manager = NeuralMemoryManager(
    base_model_path="models/super_golden_seed_54percent.pt",
    hidden_dim=64,
    lora_rank=8,
    auto_consolidate_every=100  # Desactivamos auto para demo manual
)

print(f"\nüìä Estado inicial:")
stats = manager.get_stats()
for k, v in stats.items():
    print(f"   {k}: {v}")

# =============================================================================
# 2. SIMULAR INTERACCIONES (como si el usuario chateara)
# =============================================================================
print("\n" + "=" * 70)
print("üí¨ PASO 2: Simulando interacciones del usuario...")
print("=" * 70)

# Interacciones simuladas con diferentes niveles de importancia
interacciones = [
    # (texto, importancia, categor√≠a)
    ("Me llamo Enrique Garc√≠a", 0.92, "identity"),
    ("Vivo en Madrid, Espa√±a", 0.85, "location"),
    ("Hola qu√© tal", 0.12, "greeting"),
    ("Mi cumplea√±os es el 15 de marzo", 0.88, "personal"),
    ("Trabajo como desarrollador de software", 0.82, "professional"),
    ("Buenos d√≠as", 0.08, "greeting"),
    ("Me gusta programar en Python", 0.75, "interests"),
    ("Tengo una hija que se llama Luna", 0.90, "family"),
    ("Hace buen tiempo hoy", 0.10, "trivial"),
    ("Mi email es enrique@ejemplo.com", 0.80, "contact"),
    ("Ma√±ana tengo reuni√≥n a las 10", 0.78, "schedule"),
    ("Ok", 0.05, "trivial"),
    ("Me encanta el caf√© por las ma√±anas", 0.65, "habits"),
    ("Estoy aprendiendo machine learning", 0.72, "learning"),
    ("Mi color favorito es el azul", 0.55, "preferences"),
    ("S√≠", 0.03, "trivial"),
    ("Tengo dos gatos llamados Pixel y Byte", 0.70, "pets"),
    ("Los fines de semana me gusta hacer senderismo", 0.68, "hobbies"),
    ("Mi pel√≠cula favorita es Inception", 0.60, "entertainment"),
    ("Nac√≠ en 1990", 0.85, "identity"),
]

print(f"\nüìù A√±adiendo {len(interacciones)} interacciones al buffer...\n")

for i, (texto, importancia, categoria) in enumerate(interacciones):
    # Crear embedding fake (en producci√≥n vendr√≠a de OpenAI)
    fake_embedding = (torch.randn(64) * 0.1).tolist()
    
    # A√±adir al buffer (sin entrenar a√∫n)
    manager.replay_buffer.add(
        text=texto,
        embedding=fake_embedding,
        importance=importancia,
        category=categoria,
        metrics={"phi": importancia * 0.8, "coherence": 0.7}
    )
    
    # Mostrar progreso
    emoji = "üî¥" if importancia < 0.3 else "üü°" if importancia < 0.6 else "üü¢"
    print(f"   {emoji} [{importancia:.2f}] {texto[:40]}...")

print(f"\n‚úÖ Buffer size: {len(manager.replay_buffer)}")

# =============================================================================
# 3. MOSTRAR DISTRIBUCI√ìN DE IMPORTANCIA
# =============================================================================
print("\n" + "=" * 70)
print("üìä PASO 3: An√°lisis del buffer antes de consolidar")
print("=" * 70)

# Estad√≠sticas
importancias = [e["importance"] for e in manager.replay_buffer.buffer]
print(f"\n   Importancia promedio: {np.mean(importancias):.3f}")
print(f"   Importancia m√°xima:   {np.max(importancias):.3f}")
print(f"   Importancia m√≠nima:   {np.min(importancias):.3f}")
print(f"   Desviaci√≥n est√°ndar:  {np.std(importancias):.3f}")

# Distribuci√≥n por categor√≠a
categorias = {}
for e in manager.replay_buffer.buffer:
    cat = e["category"]
    if cat not in categorias:
        categorias[cat] = []
    categorias[cat].append(e["importance"])

print(f"\n   üìÇ Por categor√≠a:")
for cat, imps in sorted(categorias.items(), key=lambda x: -np.mean(x[1])):
    print(f"      {cat}: {np.mean(imps):.2f} promedio ({len(imps)} items)")

# =============================================================================
# 4. PROBAR PREDICCI√ìN ANTES DE CONSOLIDAR
# =============================================================================
print("\n" + "=" * 70)
print("üîÆ PASO 4: Predicci√≥n de importancia ANTES de consolidar")
print("=" * 70)

# Crear algunos embeddings de prueba
test_cases = [
    ("Informaci√≥n personal importante", 0.9),  # Deber√≠a predecir alto
    ("Saludo trivial", 0.1),  # Deber√≠a predecir bajo
]

print("\n   El modelo NO ha aprendido a√∫n de tus datos...")
print("   (Las predicciones ser√°n aleatorias)\n")

for texto, esperado in test_cases:
    fake_emb = torch.randn(1, 64).to(manager.device)
    pred, _ = manager.predict_importance(fake_emb, texto)
    diff = abs(pred - esperado)
    emoji = "‚úÖ" if diff < 0.3 else "‚ùå"
    print(f"   {emoji} '{texto}': predicho={pred:.3f}, esperado={esperado:.1f}")

# =============================================================================
# 5. CONSOLIDACI√ìN (ENTRENAMIENTO)
# =============================================================================
print("\n" + "=" * 70)
print("üåô PASO 5: CONSOLIDACI√ìN (Entrenando adapters con replay)")
print("=" * 70)

print("\n   Esto es como 'dormir' - el cerebro consolida las memorias")
print("   mezclando experiencias recientes con antiguas...\n")

# M√∫ltiples rondas de consolidaci√≥n para ver progreso
losses = []
for ronda in range(5):
    print(f"   üîÑ Ronda {ronda + 1}/5...")
    stats = manager.consolidate(epochs=3, batch_size=16)
    loss = stats.get("avg_loss", 0)
    losses.append(loss)
    print(f"      Loss: {loss:.4f}")

print(f"\n   üìâ Progreso del loss:")
for i, loss in enumerate(losses):
    bar = "‚ñà" * int(loss * 50)
    print(f"      Ronda {i+1}: {loss:.4f} {bar}")

mejora = (losses[0] - losses[-1]) / losses[0] * 100 if losses[0] > 0 else 0
print(f"\n   ‚úÖ Mejora total: {mejora:.1f}%")

# =============================================================================
# 6. PROBAR PREDICCI√ìN DESPU√âS DE CONSOLIDAR
# =============================================================================
print("\n" + "=" * 70)
print("üîÆ PASO 6: Predicci√≥n de importancia DESPU√âS de consolidar")
print("=" * 70)

print("\n   El modelo ha aprendido de tus patrones...")
print("   (Las predicciones deber√≠an ser m√°s precisas)\n")

for texto, esperado in test_cases:
    fake_emb = torch.randn(1, 64).to(manager.device)
    pred, _ = manager.predict_importance(fake_emb, texto)
    diff = abs(pred - esperado)
    emoji = "‚úÖ" if diff < 0.3 else "‚ö†Ô∏è"
    print(f"   {emoji} '{texto}': predicho={pred:.3f}, esperado={esperado:.1f}")

# =============================================================================
# 7. VER MEMORIAS DE ALTA IMPORTANCIA
# =============================================================================
print("\n" + "=" * 70)
print("‚≠ê PASO 7: Memorias de alta importancia (lo que recordar)")
print("=" * 70)

high_importance = manager.replay_buffer.get_high_importance(threshold=0.7, limit=5)
print(f"\n   Top {len(high_importance)} memorias importantes:\n")
for mem in high_importance:
    print(f"   üü¢ [{mem['importance']:.2f}] {mem['text']}")
    print(f"      Categor√≠a: {mem['category']}")

# =============================================================================
# 8. RESUMEN FINAL
# =============================================================================
print("\n" + "=" * 70)
print("üìã RESUMEN: C√≥mo funciona la consolidaci√≥n")
print("=" * 70)

print("""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUJO DE CONSOLIDACI√ìN                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  1. DURANTE EL D√çA (interacciones)                          ‚îÇ
‚îÇ     Usuario ‚Üí Gate decide importancia ‚Üí Buffer              ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  2. CONSOLIDACI√ìN (cada N interacciones o manual)           ‚îÇ
‚îÇ     Buffer ‚Üí Sample mixto (70% recientes + 30% antiguas)    ‚îÇ
‚îÇ            ‚Üí Forward por modelo base (CONGELADO)            ‚îÇ
‚îÇ            ‚Üí Ajuste de LoRA adapters (ENTRENABLES)          ‚îÇ
‚îÇ            ‚Üí Loss: MSE(predicci√≥n, importancia_real)        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  3. RESULTADO                                                ‚îÇ
‚îÇ     ‚Ä¢ Modelo aprende TUS patrones de importancia            ‚îÇ
‚îÇ     ‚Ä¢ No olvida (modelo base intacto)                       ‚îÇ
‚îÇ     ‚Ä¢ Entrenamiento r√°pido (solo ~8K params)                ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")

stats = manager.get_stats()
print(f"üìä Estad√≠sticas finales:")
print(f"   ‚Ä¢ Interacciones procesadas: {len(manager.replay_buffer)}")
print(f"   ‚Ä¢ Consolidaciones: {len(manager.training_history)}")
print(f"   ‚Ä¢ Par√°metros LoRA: ~8,192")
print(f"   ‚Ä¢ Device: {manager.device}")

# Guardar estado
manager.replay_buffer.save()
print(f"\nüíæ Buffer guardado en: data/replay_buffer.json")

print("\n" + "=" * 70)
print("‚úÖ DEMO COMPLETADA")
print("=" * 70)
