"""
Entrenamiento r√°pido del Gate para distinguir trivialidades.
El Gate debe aprender a dar importance bajo a saludos/cortes√≠as.
"""
import torch
import torch.nn as nn
import torch.optim as optim
import os

# ============================================================================
# DATOS DE ENTRENAMIENTO
# ============================================================================

TRIVIAL_PHRASES = [
    # Saludos b√°sicos
    "hola", "hello", "hi", "hey", "buenas", "buenos d√≠as", "buenas tardes", 
    "buenas noches", "qu√© tal", "c√≥mo est√°s", "c√≥mo va", "qu√© hay",
    "hola qu√© tal", "hey qu√© pasa", "buenas qu√© tal",
    # Cortes√≠as
    "gracias", "de nada", "por favor", "perd√≥n", "disculpa", "lo siento",
    "muchas gracias", "gracias por todo", "te lo agradezco",
    # Afirmaciones simples
    "ok", "vale", "s√≠", "no", "claro", "entendido", "perfecto", "genial",
    "bien", "mal", "regular", "m√°s o menos", "ya", "aj√°", "mmm", "ah", "oh",
    "de acuerdo", "est√° bien", "vale vale", "okey", "oki",
    # Despedidas
    "adi√≥s", "chao", "bye", "hasta luego", "nos vemos", "hasta ma√±ana",
    "que te vaya bien", "cu√≠date", "hasta pronto",
    # Relleno
    "pues", "bueno", "entonces", "a ver", "veamos", "oye", "mira",
    "vamos a ver", "d√©jame ver", "espera", "un momento",
    # Preguntas vac√≠as (no aportan info nueva)
    "c√≥mo", "qu√©", "cu√°l", "d√≥nde", "cu√°ndo", "por qu√©",
    "qu√© pasa", "qu√© tal", "c√≥mo vas", "qu√© dices",
    "cu√©ntame algo sobre ti", "h√°blame de ti", "qu√© me cuentas",
    "cuentame algo sobre ti", "hablame de ti", "que me cuentas",  # sin tildes
    "cuentame sobre ti", "hablame sobre ti", "cuentame de ti",
    "y t√∫ qu√©", "qu√© opinas", "t√∫ qu√© dices",
    # Preguntas gen√©ricas sin contexto personal
    "qu√© hora es", "qu√© d√≠a es hoy", "qu√© tiempo hace",
    "qu√© prioridades deber√≠a tener", "qu√© deber√≠a hacer",
    # Referencias vagas sin informaci√≥n (preguntas sobre personas sin dar info nueva)
    "y eso", "y qu√© m√°s", "algo m√°s", "qu√© m√°s",
    "y mi primo andr√©s", "y mi padre", "y mi madre",  # preguntas sin info nueva
    "y mi primo andres", "y mi hermano", "y mi hermana",  # sin tilde tambi√©n
    "y respecto a mi padre", "y qu√© pasa con mi madre",
    "y mi primo", "y mi t√≠o", "y mi abuelo", "y tu familia",
    "qu√© sabes de mi padre", "qu√© sabes de mi madre",
    "y juan", "y pedro", "y mar√≠a",  # nombres solos como pregunta
]

IMPORTANT_PHRASES = [
    # Identidad con datos concretos
    "me llamo Juan", "mi nombre es Mar√≠a", "soy Pedro Garc√≠a", "tengo 25 a√±os",
    "soy Enrique", "me llamo Ana L√≥pez", "mi apellido es Mart√≠nez",
    "hola infinito soy enrique", "hola me llamo carlos",
    # Contacto
    "mi tel√©fono es 666123456", "mi email es juan@gmail.com", "vivo en Madrid",
    "mi direcci√≥n es Calle Mayor 5", "mi m√≥vil es 612345678",
    # Familia con informaci√≥n concreta
    "mi hermano se llama Pedro", "mi madre es profesora", "mi padre trabaja en banco",
    "mi esposa es doctora", "tengo dos hijos", "mi hijo tiene 5 a√±os",
    "mi primo andres monta en bici", "mi hermana estudia medicina",
    "mi padre tiene una tienda", "mi abuela vive en el pueblo",
    # Preferencias y gustos
    "me gusta el f√∫tbol", "prefiero el caf√©", "mi color favorito es azul",
    "odio las espinacas", "me encanta la m√∫sica", "hago descenso en bici",
    "mi deporte favorito es el ciclismo", "me gusta correr por las ma√±anas",
    # Recordatorios y eventos
    "ma√±ana tengo cita con el m√©dico", "el viernes es mi cumplea√±os",
    "recuerda llamar a Juan", "no olvides comprar leche",
    "el s√°bado vamos a la playa", "la semana que viene tengo examen",
    # Actividades y logros
    "hoy he igualado mi mejor tiempo", "esta ma√±ana he montado la suspensi√≥n",
    "ayer termin√© el proyecto", "he conseguido el trabajo",
    "hoy he corrido 10 kil√≥metros", "acabo de aprobar el examen",
    # Informaci√≥n personal espec√≠fica
    "trabajo como ingeniero", "estudio medicina", "mi coche es rojo",
    "tengo un perro llamado Max", "nac√≠ en Barcelona",
    "peso 75 kilos", "mido 1.80 metros", "mi bici es una Scott",
    # Datos t√©cnicos/espec√≠ficos
    "el sag ideal es 25 por ciento", "uso una horquilla de 160mm",
    "mi presupuesto es 500 euros", "necesito 8 horas de sue√±o",
]

# ============================================================================
# MODELO
# ============================================================================

class TrivialityGate(nn.Module):
    """Gate especializado en detectar trivialidades."""
    
    def __init__(self, vocab_size=256, hidden_dim=64):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.position_embedding = nn.Parameter(torch.randn(1, 128, hidden_dim) * 0.02)
        
        # Transformer ligero
        self.encoder = nn.TransformerEncoderLayer(
            d_model=hidden_dim, nhead=4, dim_feedforward=hidden_dim*2,
            dropout=0.1, batch_first=True
        )
        
        # Gate de importancia
        self.importance_gate = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.GELU(),
            nn.Linear(hidden_dim // 4, 1),
            nn.Sigmoid()
        )
    
    def forward(self, input_ids):
        # input_ids: [batch, seq_len]
        x = self.embedding(input_ids)
        seq_len = input_ids.size(1)
        x = x + self.position_embedding[:, :seq_len, :]
        x = self.encoder(x)
        x = x.mean(dim=1)  # [batch, hidden]
        importance = self.importance_gate(x)  # [batch, 1]
        return importance.squeeze(-1)


def text_to_ids(text, max_len=64):
    ids = [ord(c) % 256 for c in text.lower()[:max_len]]
    if len(ids) < max_len:
        ids = ids + [0] * (max_len - len(ids))
    return torch.tensor(ids)


# ============================================================================
# ENTRENAMIENTO
# ============================================================================

def train():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üîß Dispositivo: {device}")
    
    model = TrivialityGate().to(device)
    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)
    criterion = nn.BCELoss()
    
    # Preparar datos
    trivial_ids = torch.stack([text_to_ids(p) for p in TRIVIAL_PHRASES]).to(device)
    important_ids = torch.stack([text_to_ids(p) for p in IMPORTANT_PHRASES]).to(device)
    
    trivial_labels = torch.zeros(len(TRIVIAL_PHRASES)).to(device)  # 0 = trivial
    important_labels = torch.ones(len(IMPORTANT_PHRASES)).to(device)  # 1 = importante
    
    all_ids = torch.cat([trivial_ids, important_ids])
    all_labels = torch.cat([trivial_labels, important_labels])
    
    print(f"üìä Datos: {len(trivial_ids)} triviales + {len(important_ids)} importantes")
    print(f"üìà Entrenando...")
    
    best_acc = 0
    best_separation = 0
    for epoch in range(500):  # M√°s √©pocas
        model.train()
        
        # Shuffle
        perm = torch.randperm(len(all_ids))
        ids = all_ids[perm]
        labels = all_labels[perm]
        
        # Forward
        predictions = model(ids)
        loss = criterion(predictions, labels)
        
        # A√±adir margin loss para mejor separaci√≥n
        trivial_preds = predictions[:len(TRIVIAL_PHRASES)]
        important_preds = predictions[len(TRIVIAL_PHRASES):]
        margin_loss = torch.relu(0.3 - (important_preds.mean() - trivial_preds.mean()))
        total_loss = loss + 0.5 * margin_loss
        
        # Backward
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
        
        # Evaluar
        model.eval()
        with torch.no_grad():
            preds = model(all_ids)
            predicted = (preds > 0.5).float()
            correct = (predicted == all_labels).sum().item()
            acc = correct / len(all_labels)
            
            # Scores por clase
            trivial_scores = model(trivial_ids)
            important_scores = model(important_ids)
            separation = important_scores.mean().item() - trivial_scores.mean().item()
        
        # Guardar si tiene buena accuracy Y buena separaci√≥n
        if acc >= best_acc and separation > best_separation:
            best_acc = acc
            best_separation = separation
            torch.save({
                'model_state_dict': model.state_dict(),
                'accuracy': acc,
                'separation': separation,
                'epoch': epoch
            }, 'models/triviality_gate.pt')
        
        if epoch % 50 == 0:
            print(f"  Epoch {epoch:3d}: loss={loss.item():.4f}, acc={acc*100:.1f}%, "
                  f"trivial={trivial_scores.mean().item():.3f}, important={important_scores.mean().item():.3f}, "
                  f"sep={separation:.3f}")
    
    print(f"\n‚úÖ Mejor accuracy: {best_acc*100:.1f}%")
    print(f"üìä Mejor separaci√≥n: {best_separation:.3f}")
    print(f"üíæ Modelo guardado en: models/triviality_gate.pt")
    
    # Test final con casos problem√°ticos
    print("\nüß™ Test final (casos problem√°ticos):")
    model.eval()
    with torch.no_grad():
        test_phrases = [
            ("hola", "trivial"),
            ("cuentame algo sobre ti", "trivial"),
            ("que pasa", "trivial"),
            ("como estas", "trivial"),
            ("y mi primo andres", "trivial"),
            ("hola infinito soy enrique", "importante"),
            ("mi primo andres monta en bici", "importante"),
            ("hoy he igualado mi mejor tiempo", "importante"),
            ("peso 75 kilos", "importante"),
        ]
        correct = 0
        for phrase, expected in test_phrases:
            ids = text_to_ids(phrase).unsqueeze(0).to(device)
            score = model(ids).item()
            pred = "importante" if score > 0.5 else "trivial"
            status = "‚úì" if pred == expected else "‚úó"
            if pred == expected:
                correct += 1
            print(f"  {phrase:35} ‚Üí {score:.3f} ({pred}) {status}")
        print(f"\n  Casos test: {correct}/{len(test_phrases)} correctos")


if __name__ == "__main__":
    train()
