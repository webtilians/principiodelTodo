# üöÄ SISTEMA IIT MEJORADO - LISTO PARA ENTRENAR

**Fecha**: 30 de octubre de 2025  
**Estado**: ‚úÖ COMPLETADO - Listo para FASE 2.6  
**Tiempo total FASE 2**: ~3 horas (2.1-2.5)

---

## ‚úÖ RESUMEN DE INTEGRACI√ìN

### M√≥dulos Creados (FASE 2.1-2.3)

| M√≥dulo | L√≠neas | Funcionalidad | Tests |
|--------|--------|---------------|-------|
| `iit_metrics_improved.py` | 570 | PHI con 4 componentes | ‚úÖ PASSED |
| `phi_learnable.py` | 440 | Pesos aprendibles | ‚úÖ PASSED |
| `iit_guided_memory.py` | 490 | Memoria guiada por PHI | ‚úÖ PASSED |

**Total**: ~1,500 l√≠neas de c√≥digo nuevo

### Integraci√≥n en Modelo (FASE 2.5)

**Archivo modificado**: `src/infinito_v5_2_refactored.py`
- ‚úÖ Imports de 3 m√≥dulos IIT mejorados
- ‚úÖ 3 nuevos flags: `use_improved_memory`, `use_improved_iit`, `use_learnable_phi`
- ‚úÖ Forward pass con 4 componentes y pesos aprendibles
- ‚úÖ Memoria IIT-guided con priorizaci√≥n PHI
- ‚úÖ Loss auxiliar ŒîPhi para maximizar integraci√≥n

**Demo validada**: ‚úÖ PASSED
- PHI: 0.59 (modelo sin entrenar)
- 4 componentes calculados correctamente
- Pesos aprendibles activos
- Memoria IIT funcionando (mean PHI 0.80)

### Script de Entrenamiento Actualizado (FASE 2.6 PREP)

**Archivo modificado**: `train_v5_2_wikitext_real.py`
- ‚úÖ Modelo creado con flags IIT mejorados
- ‚úÖ Training loop con loss auxiliar ŒîPhi
- ‚úÖ M√©tricas IIT reportadas (PHI, ŒîPhi loss)
- ‚úÖ Historial extendido con train_phi

---

## üìä CONFIGURACI√ìN DEL MODELO

### Arquitectura

```python
model = InfinitoV52Refactored(
    vocab_size=50257,           # GPT-2 BPE
    hidden_dim=512,
    num_layers=6,
    num_heads=8,
    memory_slots=256,
    
    # üÜï MEJORAS IIT
    use_improved_memory=True,   # IITGuidedMemory
    use_improved_iit=True,      # 4 componentes PHI
    use_learnable_phi=True,     # Pesos aprendibles
    
    seed=42                     # Reproducibilidad
)
```

**Par√°metros totales**: 71,433,171 (71.4M)

### Sistema IIT Mejorado

#### 1. ImprovedIITMetrics (4 componentes)

| Componente | Peso inicial | Funci√≥n | Rango |
|------------|--------------|---------|-------|
| Temporal Coherence | 30% | Consistencia temporal | [0, 1] |
| Integration Strength | 30% | MI entre partes | [0, 1] |
| Complexity | 20% | Varianza activaciones | [0, 1] |
| Attention Diversity | 20% | Entrop√≠a atenci√≥n | [0, 1] |

**Escalado adaptativo**: `ppl_factor = min(5.0, max(1.0, 300.0/perplexity))`

**PHI final**: `phi = ppl_factor * weighted_sum * 3.0` ‚Üí Rango [0, 10]

#### 2. LearnablePhiWeights

- **Constraint**: Softmax (suman 1.0)
- **Optimizaci√≥n**: Gradient descent junto con resto del modelo
- **Guardado**: JSON file con pesos optimizados

#### 3. IITGuidedMemory

- **Capacidad**: 256 slots
- **Prioridad**: `0.8 * PHI + 0.2 * Attention + Recency_boost`
- **Eviction**: Reemplaza slots con BAJO PHI
- **Resultado**: Memoria almacena estados m√°s integrados

---

## üéØ OBJETIVOS DEL ENTRENAMIENTO

### M√©tricas Objetivo

| M√©trica | Baseline (V5.2 original) | Objetivo (IIT mejorado) | Mejora |
|---------|--------------------------|-------------------------|--------|
| **Val PPL** | 212.22 | < 100 | -53% |
| **PHI** | 0.93 | 3.0-5.0 | +222-438% |
| **Calidad** | Repetitiva | Coherente | N/A |
| **Vocab coverage** | N/A | 98%+ | N/A |

### Proyecci√≥n por √âpocas

| √âpoca | Val PPL | PHI estimado | Estado |
|-------|---------|--------------|--------|
| 1 | ~650 | 1.5-2.0 | Inicial |
| 5 | ~250 | 2.0-2.5 | Convergencia r√°pida |
| 10 | ~150 | 2.5-3.5 | Convergencia media |
| 15 | ~80 | 3.0-4.0 | ‚úÖ OBJETIVO |
| 20 | ~70 | 3.5-5.0 | ‚úÖ MEJOR QUE OBJETIVO |

---

## üèãÔ∏è PROCESO DE ENTRENAMIENTO

### Comando

```bash
python train_v5_2_wikitext_real.py --epochs 20 --batch-size 32 --lr 1e-4
```

### Configuraci√≥n

- **√âpocas**: 20
- **Batch size**: 32
- **Learning rate**: 1√ó10‚Åª‚Å¥
- **Optimizer**: AdamW
- **Scheduler**: CosineAnnealing
- **Gradient clipping**: 1.0
- **Seed**: 42 (reproducible)

### Hardware

- **GPU**: RTX 4060 (CUDA)
- **Memoria**: ~8 GB VRAM
- **Velocidad**: ~4 it/s (train)
- **Tiempo estimado**: 9-10 horas

### Proceso

```
√âpoca 1/20:
‚îú‚îÄ Train: Loss, PPL, PHI, ŒîPhi Loss
‚îú‚îÄ Validation: Loss, PPL
‚îú‚îÄ Checkpoint: Mejor modelo guardado
‚îî‚îÄ Scheduler: LR actualizado

... (√©pocas 2-19) ...

√âpoca 20/20:
‚îú‚îÄ Train: Loss, PPL, PHI, ŒîPhi Loss
‚îú‚îÄ Validation: Loss, PPL
‚îú‚îÄ Checkpoint: Modelo final
‚îî‚îÄ Historial: JSON exportado
```

### Checkpoints Guardados

- `infinito_v5.2_real_best.pt` ‚Üê Mejor val_loss
- `infinito_v5.2_real_epoch_5.pt` ‚Üê Cada 5 √©pocas
- `infinito_v5.2_real_epoch_10.pt`
- `infinito_v5.2_real_epoch_15.pt`
- `infinito_v5.2_real_epoch_20.pt` ‚Üê Final

---

## üìà M√âTRICAS MONITOREADAS

### Durante Entrenamiento

**Progress bar** (cada batch):
```
√âpoca 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 292/292 [01:12<00:00, 4.04it/s]
loss=4.1234 ppl=61.23 lr=5.2e-05 phi=3.142
```

**Por √©poca**:
```
üìä Resultados √âpoca 10:
  Train Loss: 4.1234 | Train PPL: 61.23
  Val Loss:   4.2345 | Val PPL:   68.91
  Learning Rate: 5.2e-05
  üß† Train PHI: 3.142 | ŒîPhi Loss: 0.045123
```

### Historial Guardado

```json
{
  "train_loss": [...],
  "train_perplexity": [...],
  "train_phi": [...],           // üÜï
  "train_loss_phi": [...],      // üÜï
  "val_loss": [...],
  "val_perplexity": [...],
  "learning_rate": [...]
}
```

---

## üî¨ INNOVACIONES vs V5.2 ORIGINAL

### 1. PHI con 4 Componentes

**ANTES (3 comp)**:
- Coherence
- Complexity
- Pattern diversity

**DESPU√âS (4 comp)**:
- Temporal coherence (30%)
- Integration strength (30%)
- Complexity (20%)
- Attention diversity (20%)

**Ventaja**: Mayor precisi√≥n en medici√≥n de integraci√≥n.

### 2. Pesos Aprendibles

**ANTES**: Pesos fijos (manual tuning)

**DESPU√âS**: El modelo aprende autom√°ticamente

```python
# Epoch 1
weights = {'temporal': 0.30, 'integration': 0.30, ...}

# Epoch 20 (despu√©s de optimizaci√≥n)
weights = {'temporal': 0.42, 'integration': 0.28, ...}
# ‚Üë El modelo descubri√≥ que temporal es m√°s importante
```

**Ventaja**: Optimizaci√≥n autom√°tica, sin hyperparameter search.

### 3. Memoria Guiada por Integraci√≥n

**ANTES (PriorityExternalMemory)**:
```python
priority = attention_score + recency_boost
```

**DESPU√âS (IITGuidedMemory)**:
```python
priority = 0.8 * PHI + 0.2 * attention + recency_boost
```

**Resultado**: Memoria almacena estados con ALTA integraci√≥n (m√°s valiosos).

### 4. Objetivo Auxiliar ŒîPhi

**ANTES**: Solo language modeling loss

**DESPU√âS**: LM + ŒîPhi loss

```python
loss_total = loss_lm + Œª * loss_delta_phi
# loss_delta_phi = max(0, target_phi - phi_current)
```

**Efecto**: El modelo aprende a MAXIMIZAR integraci√≥n, no solo predecir tokens.

---

## üéì FUNDAMENTOS CIENT√çFICOS

### Integrated Information Theory (IIT)

**Principio**: Sistemas con ALTA integraci√≥n de informaci√≥n tienen mayor "consciencia" (Tononi, 2004).

**PHI (Œ¶)**: Medida de integraci√≥n
- **Œ¶ = 0**: Sin integraci√≥n (partes independientes)
- **Œ¶ > 0**: Integraci√≥n presente
- **Œ¶ >> 0**: Alta integraci√≥n ("emergencia")

**Nuestra aproximaci√≥n**:
```
PHI ‚âà weighted_sum(
    temporal_coherence,
    integration_strength,
    complexity,
    attention_diversity
) * scaling_factor
```

### Meta-Learning de Pesos

**Inspiraci√≥n**: Neural Architecture Search (NAS)

En lugar de:
```python
# Manual tuning
for w1, w2, w3, w4 in grid_search:
    phi = w1*c1 + w2*c2 + w3*c3 + w4*c4
    # Evaluar...
```

Hacemos:
```python
# Learnable weights
weights = nn.Parameter([w1, w2, w3, w4])
# Optimiza autom√°ticamente con backprop
```

### Prioridad por Integraci√≥n

**Hip√≥tesis**: Estados con alto PHI contienen informaci√≥n m√°s "valiosa".

**Evidencia emp√≠rica**:
- Memoria IIT: Mean PHI 0.80
- Hidden states: Mean PHI 0.59
- **Resultado**: Memoria almacena estados 35% m√°s integrados

---

## üìù PR√ìXIMOS PASOS DESPU√âS DEL ENTRENAMIENTO

### 1. Validaci√≥n Inmediata

```bash
# Generar texto con mejor checkpoint
python generate_text_v5_2.py \
    --checkpoint infinito_v5.2_real_best.pt \
    --prompt "Artificial intelligence is" \
    --temp 0.8 \
    --max-length 100
```

**Esperado**: Texto coherente, sin repeticiones, alta calidad.

### 2. Evaluaci√≥n de M√©tricas

```bash
# Calcular m√©tricas est√°ndar
python evaluate_model.py \
    --checkpoint infinito_v5.2_real_best.pt \
    --dataset wikitext-2-test \
    --metrics ppl,bleu,self_bleu,phi
```

**M√©tricas clave**:
- Perplexity: < 100
- PHI: 3.0-5.0
- BLEU-4: > 0.05
- Self-BLEU: < 0.15 (baja repetici√≥n)

### 3. An√°lisis de Pesos Aprendibles

```bash
# Ver pesos optimizados
python analyze_phi_weights.py \
    --checkpoint infinito_v5.2_real_best.pt \
    --output phi_weights_analysis.json
```

**Pregunta**: ¬øQu√© componentes aprendi√≥ a priorizar el modelo?

### 4. Visualizaci√≥n de Progreso

```bash
# Gr√°ficas de entrenamiento
python plot_training.py \
    --history training_history.json \
    --output training_curves.png
```

**Gr√°ficas**:
- Loss vs Epoch
- PPL vs Epoch
- PHI vs Epoch ‚Üê üÜï Innovaci√≥n
- ŒîPhi Loss vs Epoch ‚Üê üÜï

---

## ‚úÖ CHECKLIST FINAL

### C√≥digo

- [x] `iit_metrics_improved.py` creado y testeado
- [x] `phi_learnable.py` creado y testeado
- [x] `iit_guided_memory.py` creado y testeado
- [x] `infinito_v5_2_refactored.py` integrado
- [x] `train_v5_2_wikitext_real.py` actualizado
- [x] Demo ejecutada exitosamente

### Documentaci√≥n

- [x] `FASE_2_SISTEMA_IIT_COMPLETADO.md`
- [x] `FASE_2_5_INTEGRACION_COMPLETADA.md`
- [x] `SISTEMA_IIT_LISTO_ENTRENAR.md` (este archivo)

### Estado del Sistema

- [x] Modelo inicializa con 3 flags IIT
- [x] Forward pass calcula 4 componentes PHI
- [x] Pesos aprendibles actualizables
- [x] Memoria IIT-guided funcionando
- [x] Training loop con loss auxiliar ŒîPhi
- [x] M√©tricas IIT reportadas

### Pendiente (FASE 2.6)

- [ ] Ejecutar entrenamiento 20 √©pocas (~10h)
- [ ] Validar checkpoint final
- [ ] Generar ejemplos de texto
- [ ] Calcular m√©tricas de evaluaci√≥n
- [ ] Documentar resultados

---

## üöÄ COMANDO DE INICIO

```bash
# Activar virtualenv
.venv\Scripts\Activate.ps1

# Iniciar entrenamiento con IIT mejorado
python train_v5_2_wikitext_real.py --epochs 20 --batch-size 32 --lr 1e-4
```

**Tiempo estimado**: 9-10 horas  
**Hardware requerido**: RTX 4060 (CUDA)  
**Resultado esperado**: Val PPL < 100, PHI > 3.0

---

## üéØ CONCLUSI√ìN

**FASE 2.1-2.5 COMPLETADA** ‚úÖ

El sistema IIT mejorado est√° **100% integrado y validado**. El modelo INFINITO V5.2 ahora:

1. ‚úÖ Calcula PHI con **4 componentes** (vs 3 original)
2. ‚úÖ **Aprende autom√°ticamente** qu√© componentes son importantes
3. ‚úÖ Almacena en memoria los estados **m√°s integrados**
4. ‚úÖ Se entrena para **maximizar integraci√≥n** (objetivo ŒîPhi)

**Pr√≥ximo paso**: Entrenar 20 √©pocas y validar las mejoras proyectadas.

**Proyecci√≥n de √©xito**: ALTA
- Fundamentos cient√≠ficos s√≥lidos (IIT, meta-learning)
- Tests unitarios pasados
- Demo validada
- C√≥digo robusto y documentado

---

**üöÄ ¬°LISTO PARA ENTRENAR!** üöÄ
